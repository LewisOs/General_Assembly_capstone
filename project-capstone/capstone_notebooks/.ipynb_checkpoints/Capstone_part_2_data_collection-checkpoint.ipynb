{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Part 2: Dataset + Data Collection\n",
    "\n",
    "## Overview\n",
    "\n",
    "Based on the feedback you received from your lightning talk, choose **one** of your topic areas to move forward. For Part 2, you'll need to collect, clean, and document the dataset(s) you intend to use for your project.\n",
    "\n",
    "This is not always a trivial task. Remember that data acquisition, transformation, and cleaning are typically the most time-consuming parts of data science projects, so don’t procrastinate!\n",
    "\n",
    "Once you have your data, read into it and review it to confirm whether it is as productive as you intended. If not, switch datasets, gather additional data (e.g. multiple datasets), or revise your project goals.\n",
    "\n",
    "Create your own database and data dictionary, then clean and munge your data as appropriate. Finally, document your work so far.\n",
    "\n",
    "**Goal**: Find the data you need for your project, clean, and document it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Requirements\n",
    "\n",
    "1. Find and Clean Your Data: Source and format the required data for your project.\n",
    "   - Create a database\n",
    "   - Create a data dictionary\n",
    "2. Perform preliminary data munging and cleaning of your data: organize your data relevant to your project goals.\n",
    "   - Review data to verify initial assumptions\n",
    "   - Clean and munge data as necessary\n",
    "3. Describe your data: keep your intended audience(s) in mind.\n",
    "   - Document your work so far in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scrape 1 - geting advert URLs\n",
    "\n",
    "To do - refactor this section so scrape is a single loop, not one per animal type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "\n",
    "import re\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I am sourcing my data by webscraping pets4homes.co.uk. My main goal is to scrape information for each current listing for dogs and cats. Time permitting, I may also go back and scrape other animal listings too.\n",
    "\n",
    "My plan to source the data requires two rounds a webscraping. The first round will loop through each page of search results and access the url associated with each listing. After removing any duplicates returned by this scrape, I will use the scraped urls to view each listing and scrape it's relevant information.\n",
    "\n",
    "**N.B.** *A quick warning from the outset - because of some issues I had during scraping, I ended up writing this code with a lot of repetition (rather than using loops and functions). As such, part 1 & 2 of the scrape are badly in need of refactoring. The cleaning section is, well, cleaner.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### URL scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# importing a page of manually scraped html to be used for developing functions/code\n",
    "\n",
    "path = '/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/dogs_html.rtf'\n",
    "\n",
    "with open(path) as f:\n",
    "    html = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# function to extract urls from search pages\n",
    "\n",
    "def get_url(page):\n",
    "    '''    \n",
    "    Extracts Pets4Homes advert listing URLs from a page of search results:\n",
    "    \n",
    "    Takes a BeautifulSoup object as input. Finds all instances of the class storing each an advert listing's\n",
    "    URL. Adds each unique URL to a list. Returns the list.\n",
    "    \n",
    "    ---------\n",
    "    Arguments\n",
    "    ---------\n",
    "    page : bs4.BeautifulSoup\n",
    "        the html for a Pets4Homes search page, encoded as a BeautifulSoup object\n",
    "    \n",
    "    ---------\n",
    "    Returns\n",
    "    ---------\n",
    "    cur_page_listing_urls : list\n",
    "        a list containg the URLs for each advert listed in page\n",
    "    '''\n",
    "    \n",
    "    cur_page_listing_urls = []\n",
    "\n",
    "    # n.b. Pets4Home's HTML class names appear to change on a daily basis. 'ib iu' works as I am writing this\n",
    "    # comment, but may not when you are reading it.\n",
    "    \n",
    "    for a in page.find_all('a', class_=\"ab Ym\"):\n",
    "        url = 'https://www.pets4homes.co.uk' + a['href']\n",
    "        if url in cur_page_listing_urls:\n",
    "            continue\n",
    "        else:\n",
    "            cur_page_listing_urls.append(url)\n",
    "    \n",
    "    return cur_page_listing_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# testing get_url\n",
    "get_url(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# getting dogs urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "for page_num in range(1,501):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/puppies/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))    \n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "dogs = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "dogs = pd.DataFrame(dogs, columns = ['URLs'])\n",
    "\n",
    "# exporting to csv\n",
    "dogs.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/dogs_ulrs_10-01-23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/bhhhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/n-9id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/yblc-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/b4ei5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/j0vow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/hjb6l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/pqe3z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/owqq6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/pyigz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7922</th>\n",
       "      <td>https://www.pets4homes.co.uk/classifieds/zshts...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7923 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URLs\n",
       "0     https://www.pets4homes.co.uk/classifieds/bhhhe...\n",
       "1     https://www.pets4homes.co.uk/classifieds/n-9id...\n",
       "2     https://www.pets4homes.co.uk/classifieds/yblc-...\n",
       "3     https://www.pets4homes.co.uk/classifieds/b4ei5...\n",
       "4     https://www.pets4homes.co.uk/classifieds/j0vow...\n",
       "...                                                 ...\n",
       "7918  https://www.pets4homes.co.uk/classifieds/hjb6l...\n",
       "7919  https://www.pets4homes.co.uk/classifieds/pqe3z...\n",
       "7920  https://www.pets4homes.co.uk/classifieds/owqq6...\n",
       "7921  https://www.pets4homes.co.uk/classifieds/pyigz...\n",
       "7922  https://www.pets4homes.co.uk/classifieds/zshts...\n",
       "\n",
       "[7923 rows x 1 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking output of dog search scrape\n",
    "dogs = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/dogs_ulrs_10-01-23.csv',\n",
    "                   index_col='Unnamed: 0')\n",
    "dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pages scraped, 209 to go. Time is: 11:45:51\n",
      "20 pages scraped, 199 to go. Time is: 11:46:21\n",
      "30 pages scraped, 189 to go. Time is: 11:47:00\n",
      "40 pages scraped, 179 to go. Time is: 11:47:38\n",
      "50 pages scraped, 169 to go. Time is: 11:48:28\n",
      "60 pages scraped, 159 to go. Time is: 11:49:11\n",
      "70 pages scraped, 149 to go. Time is: 11:49:47\n",
      "80 pages scraped, 139 to go. Time is: 11:50:29\n",
      "90 pages scraped, 129 to go. Time is: 11:51:02\n",
      "100 pages scraped, 119 to go. Time is: 11:51:35\n",
      "110 pages scraped, 109 to go. Time is: 11:52:09\n",
      "120 pages scraped, 99 to go. Time is: 11:52:41\n",
      "130 pages scraped, 89 to go. Time is: 11:53:19\n",
      "140 pages scraped, 79 to go. Time is: 11:53:59\n",
      "150 pages scraped, 69 to go. Time is: 11:54:44\n",
      "160 pages scraped, 59 to go. Time is: 11:55:30\n",
      "170 pages scraped, 49 to go. Time is: 11:56:16\n",
      "180 pages scraped, 39 to go. Time is: 11:57:04\n",
      "190 pages scraped, 29 to go. Time is: 11:58:02\n",
      "200 pages scraped, 19 to go. Time is: 11:59:01\n",
      "210 pages scraped, 9 to go. Time is: 11:59:55\n"
     ]
    }
   ],
   "source": [
    "# getting cats urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for page_num in range(1,219):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/kittens/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "          \n",
    "    n += 1\n",
    "    if n % 10 == 0:\n",
    "        print(f'{n} pages scraped, {219-n} to go. Time is:', time.ctime()[11:19])\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "cats = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "cats = pd.DataFrame(cats, columns = ['URLs'])\n",
    "\n",
    "# exporting to csv\n",
    "cats.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/cat_ulrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Reptiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pages scraped, 209 to go. Time is: 08:42:46\n",
      "20 pages scraped, 199 to go. Time is: 08:43:06\n",
      "30 pages scraped, 189 to go. Time is: 08:43:30\n",
      "40 pages scraped, 179 to go. Time is: 08:44:01\n",
      "50 pages scraped, 169 to go. Time is: 08:44:40\n",
      "60 pages scraped, 159 to go. Time is: 08:45:29\n",
      "70 pages scraped, 149 to go. Time is: 08:46:06\n",
      "80 pages scraped, 139 to go. Time is: 08:46:43\n",
      "90 pages scraped, 129 to go. Time is: 08:47:20\n",
      "100 pages scraped, 119 to go. Time is: 08:48:05\n",
      "110 pages scraped, 109 to go. Time is: 08:48:58\n"
     ]
    }
   ],
   "source": [
    "# getting reptiles urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for page_num in range(1,112):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/reptiles/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "          \n",
    "    n += 1\n",
    "    if n % 10 == 0:\n",
    "        print(f'{n} pages scraped, {112-n} to go. Time is:', time.ctime()[11:19])\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "reptiles = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "reptiles = pd.DataFrame(reptiles, columns = ['URLs'])\n",
    "\n",
    "# exporting to csv\n",
    "reptiles.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/reptiles_ulrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pages scraped, 97 to go. Time is: 11:21:11\n",
      "20 pages scraped, 87 to go. Time is: 11:21:28\n",
      "30 pages scraped, 77 to go. Time is: 11:21:45\n",
      "40 pages scraped, 67 to go. Time is: 11:22:04\n",
      "50 pages scraped, 57 to go. Time is: 11:22:25\n",
      "60 pages scraped, 47 to go. Time is: 11:22:45\n",
      "70 pages scraped, 37 to go. Time is: 11:23:05\n",
      "80 pages scraped, 27 to go. Time is: 11:23:25\n",
      "90 pages scraped, 17 to go. Time is: 11:23:43\n",
      "100 pages scraped, 7 to go. Time is: 11:23:55\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'reptiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_13134/2913700893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# converting to DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mbirds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreptiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'URLs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mbirds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/birds_ulrs.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reptiles' is not defined"
     ]
    }
   ],
   "source": [
    "# getting birds urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for page_num in range(1,107):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/birds/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "          \n",
    "    n += 1\n",
    "    if n % 10 == 0:\n",
    "        print(f'{n} pages scraped, {107-n} to go. Time is:', time.ctime()[11:19])\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "birds = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "birds = pd.DataFrame(birds, columns = ['URLs'])\n",
    "\n",
    "birds.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/birds_ulrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Rodents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pages scraped, 97 to go. Time is: 11:29:12\n",
      "20 pages scraped, 87 to go. Time is: 11:29:24\n",
      "30 pages scraped, 77 to go. Time is: 11:29:36\n",
      "40 pages scraped, 67 to go. Time is: 11:29:51\n",
      "50 pages scraped, 57 to go. Time is: 11:30:07\n",
      "60 pages scraped, 47 to go. Time is: 11:30:24\n",
      "70 pages scraped, 37 to go. Time is: 11:30:42\n",
      "80 pages scraped, 27 to go. Time is: 11:30:59\n"
     ]
    }
   ],
   "source": [
    "# getting rodents urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for page_num in range(1,86):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/rodents/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "          \n",
    "    n += 1\n",
    "    if n % 10 == 0:\n",
    "        print(f'{n} pages scraped, {107-n} to go. Time is:', time.ctime()[11:19])\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "rodents = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "rodents = pd.DataFrame(rodents, columns = ['URLs'])\n",
    "\n",
    "rodents.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/rodents_ulrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URLs    https://www.pets4homes.co.uk/classifieds/juq3f...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Rabbits\n",
    "\n",
    "n.b. although rabbits are rodents, they are listed separately on Pets4Homes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pages scraped, 75 to go. Time is: 11:32:27\n",
      "20 pages scraped, 65 to go. Time is: 11:32:41\n",
      "30 pages scraped, 55 to go. Time is: 11:32:54\n",
      "40 pages scraped, 45 to go. Time is: 11:33:11\n",
      "50 pages scraped, 35 to go. Time is: 11:33:27\n",
      "60 pages scraped, 25 to go. Time is: 11:33:44\n",
      "70 pages scraped, 15 to go. Time is: 11:34:02\n",
      "80 pages scraped, 5 to go. Time is: 11:34:13\n"
     ]
    }
   ],
   "source": [
    "# getting rabbits urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for page_num in range(1,86):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/rabbits/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "          \n",
    "    n += 1\n",
    "    if n % 10 == 0:\n",
    "        print(f'{n} pages scraped, {85-n} to go. Time is:', time.ctime()[11:19])\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "rabbits = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "rabbits = pd.DataFrame(rabbits, columns = ['URLs'])\n",
    "\n",
    "rabbits.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/rabbits_ulrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pages scraped, 24 to go. Time is: 11:45:24\n",
      "20 pages scraped, 14 to go. Time is: 11:45:36\n",
      "30 pages scraped, 4 to go. Time is: 11:45:48\n"
     ]
    }
   ],
   "source": [
    "# getting fish urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for page_num in range(1,35):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/fish/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "          \n",
    "    n += 1\n",
    "    if n % 10 == 0:\n",
    "        print(f'{n} pages scraped, {34-n} to go. Time is:', time.ctime()[11:19])\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "fish = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "fish = pd.DataFrame(fish, columns = ['URLs'])\n",
    "\n",
    "fish.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/fish_ulrs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pages scraped, 14 to go. Time is: 11:48:38\n",
      "20 pages scraped, 4 to go. Time is: 11:48:50\n"
     ]
    }
   ],
   "source": [
    "# getting poultry urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for page_num in range(1,25):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/poultry/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "          \n",
    "    n += 1\n",
    "    if n % 10 == 0:\n",
    "        print(f'{n} pages scraped, {24-n} to go. Time is:', time.ctime()[11:19])\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "poultry = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "poultry = pd.DataFrame(poultry, columns = ['URLs'])\n",
    "\n",
    "poultry.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/poultry_ulrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pages scraped, 4 to go. Time is: 11:52:05\n"
     ]
    }
   ],
   "source": [
    "# getting horses urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for page_num in range(1,15):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/horses/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "          \n",
    "    n += 1\n",
    "    if n % 10 == 0:\n",
    "        print(f'{n} pages scraped, {14-n} to go. Time is:', time.ctime()[11:19])\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "horses = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "horses = pd.DataFrame(horses, columns = ['URLs'])\n",
    "\n",
    "horses.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/horses_ulrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Invertebrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# getting invertebrates urls\n",
    "\n",
    "# launching Chrome\n",
    "dr = webdriver.Chrome()\n",
    "\n",
    "listing_urls = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for page_num in range(1,10):\n",
    "    \n",
    "    URL = f'https://www.pets4homes.co.uk/sale/invertebrates/local/local/page-{page_num}/'\n",
    "    \n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    listing_urls.append(get_url(page))\n",
    "          \n",
    "    n += 1\n",
    "    if n % 10 == 0:\n",
    "        print(f'{n} pages scraped, {9-n} to go. Time is:', time.ctime()[11:19])\n",
    "\n",
    "# flattening list of lists and dropping duplicates\n",
    "invertebrates = set([item for sublist in listing_urls for item in sublist])\n",
    "\n",
    "# converting to DataFrame\n",
    "invertebrates = pd.DataFrame(invertebrates, columns = ['URLs'])\n",
    "\n",
    "invertebrates.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/invertebrates_ulrs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scrape 2 - getting listings' HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I had initially designed my 2nd scraper loop to pull up each advert listing one by one, extract the relevent data and add it to a DataFrame. This would allow me to only save the information I need, not the full html for each listing. \n",
    "\n",
    "Unfortunately, I discovered that Pets4Homes changes its HTML class names on a regular (I think daily) basis. This was causing problems because code that I had written to extract the relevant information on one day would stop working the next. Although this didn't happen, it is also possible that Pets4Homes could have updated their class names whilst I was in a middle of a scrape. Any scrapes after the change would return no/wrong information, but this wouldn't become clear until the scrape was finished (which would have been a considerable time waste).\n",
    "\n",
    "Given the problems outlined above, I have changed my approach so that my 2nd scraper loop will save the full html for each advert. I will then process the saved html in a 3rd to extract relevant information. This will ensure that I can work on writing information extraction code without worrying about a Pets4Homes update making it obsolete.\n",
    "\n",
    "The shortcoming of this approach is that the code written for the 3rd step will only work for the pages I've already scraped, not for future scrapes. It might be possible to write a 2nd scraper loop which is uneffected by Pets4Homes' changing html classes, but I felt that given the timeframe, the approach I have chosen was safer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 7910\n",
    "\n",
    "dogs_html = []\n",
    "\n",
    "for page in dogs['URLs'][n:]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    dogs_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(n, 'Time is:', time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dogs_html_strs = [str(i) for i in dogs_html]\n",
    "\n",
    "dogs_html_strs_DF = pd.DataFrame(data = dogs_html_strs, columns = ['URLs'])\n",
    "dogs_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3612"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dogs_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/dogs_html_strs_(7910-to-7923)_11-01-23')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Time is: 20:46:04\n",
      "100 Time is: 20:48:49\n",
      "150 Time is: 20:51:00\n",
      "200 Time is: 20:53:52\n",
      "250 Time is: 20:57:16\n",
      "300 Time is: 21:00:17\n",
      "350 Time is: 21:03:47\n",
      "371\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 0\n",
    "\n",
    "cats_html = []\n",
    "\n",
    "for page in cats['URLs'][0:371]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    cats_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(n, 'Time is:', time.ctime()[11:19])\n",
    "    \n",
    "print(len(cats_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;style class=\"vjs-styles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;style class=\"vjs-styles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "1  <html lang=\"en\"><head><style class=\"vjs-styles...\n",
       "2  <html lang=\"en\"><head><style class=\"vjs-styles...\n",
       "3  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "4  <html lang=\"en\"><head><link as=\"script\" href=\"..."
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats_html_strs = [str(i) for i in cats_html]\n",
    "\n",
    "cats_html_strs_DF = pd.DataFrame(data = cats_html_strs, columns = ['URLs'])\n",
    "cats_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cats_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/cats_listing_scrapes_(0-to-371).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Reptiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 Time is: 13:12:26\n",
      "1650 Time is: 13:13:38\n",
      "1700 Time is: 13:14:46\n",
      "1750 Time is: 13:15:55\n",
      "1800 Time is: 13:17:17\n",
      "1850 Time is: 13:18:57\n",
      "1900 Time is: 13:20:55\n",
      "1950 Time is: 13:23:11\n",
      "2000 Time is: 13:25:51\n",
      "2050 Time is: 13:29:05\n",
      "2100 Time is: 13:31:43\n",
      "2150 Time is: 13:32:53\n",
      "612\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 1584\n",
    "\n",
    "reptiles = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/scraped_urls/reptiles_ulrs.csv',\n",
    "                      index_col = 'Unnamed: 0')\n",
    "\n",
    "reptiles_html = []\n",
    "\n",
    "for page in reptiles['URLs'][n:len(reptiles)]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    reptiles_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(n, 'Time is:', time.ctime()[11:19])\n",
    "    \n",
    "print(len(reptiles_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "1  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "2  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "3  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "4  <html lang=\"en\"><head><link as=\"script\" href=\"..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reptiles_html_strs = [str(i) for i in reptiles_html]\n",
    "\n",
    "reptiles_html_strs_DF = pd.DataFrame(data = reptiles_html_strs, columns = ['URLs'])\n",
    "reptiles_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reptiles_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/reptiles_listing_scrapes_(1584-to-612).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 scraped,180 remaining. Time is: 15:29:53\n",
      "1550 scraped,130 remaining. Time is: 15:31:21\n",
      "1600 scraped,80 remaining. Time is: 15:32:58\n",
      "1650 scraped,30 remaining. Time is: 15:34:57\n",
      "215\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 1465\n",
    "\n",
    "birds = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/scraped_urls/birds_ulrs.csv',\n",
    "                      index_col = 'Unnamed: 0')\n",
    "\n",
    "birds_html = []\n",
    "\n",
    "for page in birds['URLs'][n:len(birds)]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    birds_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(f'{n} scraped,{len(birds)-n} remaining. Time is: {time.ctime()[11:19]}')\n",
    "    \n",
    "print(len(birds_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(birds_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(birds) -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;style class=\"vjs-styles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "1  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "2  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "3  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "4  <html lang=\"en\"><head><style class=\"vjs-styles..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds_html_strs = [str(i) for i in birds_html]\n",
    "\n",
    "birds_html_strs_DF = pd.DataFrame(data = birds_html_strs, columns = ['URLs'])\n",
    "birds_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "birds_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/birds_listing_scrapes_(1465-to-end).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Rodents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 scraped,1624 remaining. Time is: 15:44:16\n",
      "100 scraped,1574 remaining. Time is: 15:46:30\n",
      "150 scraped,1524 remaining. Time is: 15:49:16\n",
      "200 scraped,1474 remaining. Time is: 15:51:51\n",
      "250 scraped,1424 remaining. Time is: 15:54:57\n",
      "300 scraped,1374 remaining. Time is: 15:58:33\n",
      "350 scraped,1324 remaining. Time is: 16:00:48\n",
      "400 scraped,1274 remaining. Time is: 16:02:32\n",
      "450 scraped,1224 remaining. Time is: 16:05:01\n",
      "500 scraped,1174 remaining. Time is: 16:07:31\n",
      "550 scraped,1124 remaining. Time is: 16:09:41\n",
      "600 scraped,1074 remaining. Time is: 16:12:24\n",
      "650 scraped,1024 remaining. Time is: 16:14:31\n",
      "700 scraped,974 remaining. Time is: 16:16:18\n",
      "750 scraped,924 remaining. Time is: 16:18:36\n",
      "800 scraped,874 remaining. Time is: 16:21:28\n",
      "850 scraped,824 remaining. Time is: 16:24:21\n",
      "900 scraped,774 remaining. Time is: 16:26:01\n",
      "950 scraped,724 remaining. Time is: 16:27:33\n",
      "1000 scraped,674 remaining. Time is: 16:29:26\n",
      "1050 scraped,624 remaining. Time is: 16:31:40\n",
      "1100 scraped,574 remaining. Time is: 16:32:56\n",
      "1150 scraped,524 remaining. Time is: 16:34:10\n",
      "1200 scraped,474 remaining. Time is: 16:35:33\n",
      "1250 scraped,424 remaining. Time is: 16:37:32\n",
      "1300 scraped,374 remaining. Time is: 16:39:27\n",
      "1350 scraped,324 remaining. Time is: 16:41:42\n",
      "1400 scraped,274 remaining. Time is: 16:43:31\n",
      "1450 scraped,224 remaining. Time is: 16:45:08\n",
      "1500 scraped,174 remaining. Time is: 16:46:27\n",
      "1550 scraped,124 remaining. Time is: 16:47:44\n",
      "1600 scraped,74 remaining. Time is: 16:48:59\n",
      "1650 scraped,24 remaining. Time is: 16:50:19\n",
      "1674\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 0\n",
    "\n",
    "rodents = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/scraped_urls/rodents_ulrs.csv',\n",
    "                      index_col = 'Unnamed: 0')\n",
    "\n",
    "rodents_html = []\n",
    "\n",
    "for page in rodents['URLs'][n:len(rodents)]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    rodents_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(f'{n} scraped,{len(rodents)-n} remaining. Time is: {time.ctime()[11:19]}')\n",
    "    \n",
    "print(len(rodents_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "1  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "2  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "3  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "4  <html lang=\"en\"><head><link as=\"script\" href=\"..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rodents_html_strs = [str(i) for i in rodents_html]\n",
    "\n",
    "rodents_html_strs_DF = pd.DataFrame(data = rodents_html_strs, columns = ['URLs'])\n",
    "rodents_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rodents_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/rodents_listing_scrapes_(all).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Rabbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 scraped,69 remaining. Time is: 23:36:26\n",
      "1350 scraped,19 remaining. Time is: 23:37:26\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 1280\n",
    "\n",
    "rabbits = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/scraped_urls/rabbits_ulrs.csv',\n",
    "                      index_col = 'Unnamed: 0')\n",
    "\n",
    "rabbits_html = []\n",
    "\n",
    "for page in rabbits['URLs'][n:len(rabbits)]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    rabbits_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(f'{n} scraped,{len(rabbits)-n} remaining. Time is: {time.ctime()[11:19]}')\n",
    "    \n",
    "print(len(rabbits_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "1  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "2  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "3  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "4  <html lang=\"en\"><head><link as=\"script\" href=\"..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rabbits_html_strs = [str(i) for i in rabbits_html]\n",
    "\n",
    "rabbits_html_strs_DF = pd.DataFrame(data = rabbits_html_strs, columns = ['URLs'])\n",
    "rabbits_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rabbits_html) + 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rabbits_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/rabbits_listing_scrapes_(1280-to-1369).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 scraped,311 remaining. Time is: 00:16:21\n",
      "400 scraped,261 remaining. Time is: 00:17:18\n",
      "450 scraped,211 remaining. Time is: 00:18:15\n",
      "500 scraped,161 remaining. Time is: 00:19:09\n",
      "550 scraped,111 remaining. Time is: 00:20:05\n",
      "600 scraped,61 remaining. Time is: 00:20:58\n",
      "650 scraped,11 remaining. Time is: 00:21:52\n",
      "329\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 332\n",
    "\n",
    "fish = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/scraped_urls/fish_ulrs.csv',\n",
    "                      index_col = 'Unnamed: 0')\n",
    "\n",
    "fish_html = []\n",
    "\n",
    "for page in fish['URLs'][n:len(fish)]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    fish_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(f'{n} scraped,{len(fish)-n} remaining. Time is: {time.ctime()[11:19]}')\n",
    "    \n",
    "print(len(fish_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;style class=\"vjs-styles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "1  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "2  <html lang=\"en\"><head><style class=\"vjs-styles...\n",
       "3  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "4  <html lang=\"en\"><head><link as=\"script\" href=\"..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_html_strs = [str(i) for i in fish_html]\n",
    "\n",
    "fish_html_strs_DF = pd.DataFrame(data = fish_html_strs, columns = ['URLs'])\n",
    "fish_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fish_html) + 332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fish_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/fish_listing_scrapes_(332-to-661).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### poultry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 scraped,411 remaining. Time is: 00:39:38\n",
      "100 scraped,361 remaining. Time is: 00:40:32\n",
      "150 scraped,311 remaining. Time is: 00:41:28\n",
      "200 scraped,261 remaining. Time is: 00:42:22\n",
      "250 scraped,211 remaining. Time is: 00:43:17\n",
      "300 scraped,161 remaining. Time is: 00:44:22\n",
      "350 scraped,111 remaining. Time is: 00:45:17\n",
      "400 scraped,61 remaining. Time is: 00:46:19\n",
      "450 scraped,11 remaining. Time is: 00:47:36\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 0\n",
    "\n",
    "poultry = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/scraped_urls/poultry_ulrs.csv',\n",
    "                      index_col = 'Unnamed: 0')\n",
    "\n",
    "poultry_html = []\n",
    "\n",
    "for page in poultry['URLs'][n:len(poultry)]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    poultry_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(f'{n} scraped,{len(poultry)-n} remaining. Time is: {time.ctime()[11:19]}')\n",
    "    \n",
    "print(len(poultry_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "1  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "2  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "3  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "4  <html lang=\"en\"><head><link as=\"script\" href=\"..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poultry_html_strs = [str(i) for i in poultry_html]\n",
    "\n",
    "poultry_html_strs_DF = pd.DataFrame(data = poultry_html_strs, columns = ['URLs'])\n",
    "poultry_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fish_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/poultry_listing_scrapes_(all).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 scraped,219 remaining. Time is: 14:40:38\n",
      "100 scraped,169 remaining. Time is: 14:42:10\n",
      "150 scraped,119 remaining. Time is: 14:43:37\n",
      "200 scraped,69 remaining. Time is: 14:45:11\n",
      "250 scraped,19 remaining. Time is: 14:46:47\n",
      "269\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 0\n",
    "\n",
    "horses = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/scraped_urls/horses_ulrs.csv',\n",
    "                      index_col = 'Unnamed: 0')\n",
    "\n",
    "horses_html = []\n",
    "\n",
    "for page in horses['URLs'][n:len(horses)]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    horses_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(f'{n} scraped,{len(horses)-n} remaining. Time is: {time.ctime()[11:19]}')\n",
    "    \n",
    "print(len(horses_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "1  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "2  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "3  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "4  <html lang=\"en\"><head><link as=\"script\" href=\"..."
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horses_html_strs = [str(i) for i in horses_html]\n",
    "\n",
    "horses_html_strs_DF = pd.DataFrame(data = horses_html_strs, columns = ['URLs'])\n",
    "horses_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "horses_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/horses_listing_scrapes_(all).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### invertebrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 scraped,118 remaining. Time is: 14:50:51\n",
      "100 scraped,68 remaining. Time is: 14:52:10\n",
      "150 scraped,18 remaining. Time is: 14:53:27\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "dr = webdriver.Chrome()\n",
    "\n",
    "# I've had to carry out this scrape in multiple stages due to selenium/chrome crashing. \n",
    "# n is the number of URLs in the dogs list which I had scraped prior to the last crash.\n",
    "n = 0\n",
    "\n",
    "invertebrates = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/scraped_urls/invertebrates_ulrs.csv',\n",
    "                      index_col = 'Unnamed: 0')\n",
    "\n",
    "invertebrates_html = []\n",
    "\n",
    "for page in invertebrates['URLs'][n:len(invertebrates)]:\n",
    "    \n",
    "    URL = page\n",
    "\n",
    "    # going to the URL\n",
    "    dr.get(URL)\n",
    "\n",
    "    # getting the html \n",
    "    html = dr.page_source\n",
    "\n",
    "    page = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    invertebrates_html.append(page)\n",
    "    \n",
    "    # output to track progress\n",
    "    n += 1 \n",
    "    if n % 50 == 0:\n",
    "        print(f'{n} scraped,{len(invertebrates)-n} remaining. Time is: {time.ctime()[11:19]}')\n",
    "    \n",
    "print(len(invertebrates_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;link as=\"script\" href=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs\n",
       "0  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "1  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "2  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "3  <html lang=\"en\"><head><link as=\"script\" href=\"...\n",
       "4  <html lang=\"en\"><head><link as=\"script\" href=\"..."
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invertebrates_html_strs = [str(i) for i in invertebrates_html]\n",
    "\n",
    "invertebrates_html_strs_DF = pd.DataFrame(data = invertebrates_html_strs, columns = ['URLs'])\n",
    "invertebrates_html_strs_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "invertebrates_html_strs_DF.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/invertebrates_listing_scrapes_(all).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data extraction\n",
    "\n",
    "I've now scraped the full html all current listings on Pets4homes.co.uk. The next step its to process this html to extract relevant the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_data(html):\n",
    "    \"\"\"\n",
    "    TO DO\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    data_dict = {}\n",
    "\n",
    "    application = soup.find('script', attrs = {'type':\"application/ld+json\"}).text.replace('\\\\n','\\n')\n",
    "    application_json = json.loads(application, strict=False)\n",
    "    \n",
    "    # TITLE\n",
    "    try:\n",
    "        data_dict['title'] = soup.find('title').text.split('|')[0]\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # PRICE\n",
    "    try:\n",
    "        data_dict['price'] = (application_json['offers']['price'])\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # URL\n",
    "    try:\n",
    "        data_dict['url'] = (application_json['offers']['url'])\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # SELLER\n",
    "    try:\n",
    "        data_dict['seller_type'] = (application_json['offers']['seller']['type'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        data_dict['seller_name'] = (application_json['offers']['seller']['name'])\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    # VERIFICATION\n",
    "    colour_dict = {'#69d4a1':1, '#c0ccda':0}\n",
    "\n",
    "    try:\n",
    "        for i in (soup.find(attrs = {'data-testid':\"verification-status-field\"})):\n",
    "            els = i.find_all()\n",
    "            colour = (els[0]['style'])\n",
    "            data_dict[els[1].text] = colour_dict[colour[13:20]]\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            contact_type = ['Phone', 'Email','Facebook', 'Google']\n",
    "            verification_status = soup.find_all(attrs = {'data-testid':\"verification-status-field\"})[:4]\n",
    "            for ct, vs in zip(contact_type, verification_status):\n",
    "                if '#69d4a1' in str(vs):\n",
    "                    data_dict[ct] = 1\n",
    "                elif '#c0ccda' in str(vs):\n",
    "                    data_dict[ct] = 0\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    # IMAGES\n",
    "    try:\n",
    "        data_dict['n_images'] = len(application_json['image'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # CATERGORY\n",
    "    try:\n",
    "        data_dict['category'] = (application_json['category']).replace(' ','').split('>')[1]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # DETAILS \n",
    "    try:\n",
    "        listing_details = soup.find(attrs = {\"data-testid\": 'listing-details'})\n",
    "        listing_params = listing_details.find_all(attrs = {\"data-testid\": 'details-parameter'})\n",
    "\n",
    "        for param in listing_params:\n",
    "\n",
    "            param_text = re.sub(\"[\\<].*?[\\>]\", \"|\", str(param))\n",
    "            param_text = param_text.split(\"|\")\n",
    "            values = []\n",
    "            for el in param_text:\n",
    "                if el != '':\n",
    "                    values.append(el)\n",
    "            data_dict[values[0]] = values[1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # DESCRIPTION\n",
    "    try:\n",
    "        data_dict['description'] = soup.find('meta', attrs = {'name':\"description\"})['content']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'breading pair of oscars ',\n",
       " 'price': '70',\n",
       " 'url': '/classifieds/taskggl35-breading-pair-of-oscars-telford/',\n",
       " 'seller_type': 'Person',\n",
       " 'seller_name': 'Phil B.',\n",
       " 'Phone': 1,\n",
       " 'Email': 1,\n",
       " 'Facebook': 1,\n",
       " 'Google': 0,\n",
       " 'n_images': 3,\n",
       " 'category': 'Fish',\n",
       " 'Adv. ID': 'tASkGGL35',\n",
       " 'Adv. Location': 'Trench, Telford',\n",
       " 'Advert Type': 'For sale',\n",
       " 'Advertiser': 'Individual',\n",
       " 'Breed': 'Cichlids',\n",
       " 'Pet Age: ': '3 days',\n",
       " 'description': 'large pair of oscars around 12 inchs 1 albino and female a tigar a proven pair of breaders no fault of there own for sale I just want a change in tank tigar oscar was Born with a lip defect but never stopped her eating and never effected her every day life must go together'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_test = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/data/data_fish_listings/fish_listing_scrapes_(0-to-332).csv')\n",
    "\n",
    "extract_data(fish_test.iloc[0].values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_birds_listing/birds_listing_scrapes_(0-to-1465).csv',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_birds_listing/birds_listing_scrapes_(1465-to-end).csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birds done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_cats_listings/cats_listing_scrapes_(0-to-371).csv',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_cats_listings/cats_listing_scrapes_(370-to-3268).csv',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_cats_listings/cats_listing_scrapes_(3268-to-3612).csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:33: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(0-to-4368)_11-01-23',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(4368-to-5561)_11-01-23',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:39: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(5561-to-6984)_11-01-23',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(6984-to-7910)_11-01-23',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(7910-to-7923)_11-01-23',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogs done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_fish_listings/fish_listing_scrapes_(0-to-332).csv',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:56: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_fish_listings/fish_listing_scrapes_(332-to-661).csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/horses_listing_scrapes_(all).csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horses done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/invertebrates_listing_scrapes_(all).csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invertebrates done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/poultry_listing_scrapes_(all).csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poultry done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:86: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/poultry_listing_scrapes_(all).csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poultry done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:93: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_rabbits_listings/rabbits_listing_scrapes_(0-to-537).csv',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_rabbits_listings/rabbits_listing_scrapes_(537-to-923).csv',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:99: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_rabbits_listings/rabbits_listing_scrapes_(923-to-1280).csv',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:102: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_rabbits_listings/rabbits_listing_scrapes_(1280-to-1369).csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rabbits done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:111: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_reptiles_listings/reptiles_listing_scrapes_(0-to-1584).csv',\n",
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:114: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/data_reptiles_listings/reptiles_listing_scrapes_(1584-to-2196).csv',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reptiles done.\n",
      "Rodents done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/2510205070.py:123: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(pd.read_csv(f'{path}/rodents_listing_scrapes_(all).csv',\n"
     ]
    }
   ],
   "source": [
    "# combining all scraped html into single df for data extraction\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "path = '/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/data'\n",
    "\n",
    "# BIRDS\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_birds_listing/birds_listing_scrapes_(0-to-1465).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_birds_listing/birds_listing_scrapes_(1465-to-end).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "print('Birds done.')\n",
    "\n",
    "\n",
    "\n",
    "# CATS\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_cats_listings/cats_listing_scrapes_(0-to-371).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_cats_listings/cats_listing_scrapes_(370-to-3268).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_cats_listings/cats_listing_scrapes_(3268-to-3612).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "print('Cats done.')\n",
    "\n",
    "\n",
    "\n",
    "# DOGS\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(0-to-4368)_11-01-23',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(4368-to-5561)_11-01-23',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(5561-to-6984)_11-01-23',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(6984-to-7910)_11-01-23',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_dogs_listings/dogs_html_strs_(7910-to-7923)_11-01-23',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "print('Dogs done.')\n",
    "\n",
    "\n",
    "\n",
    "# FISH\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_fish_listings/fish_listing_scrapes_(0-to-332).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_fish_listings/fish_listing_scrapes_(332-to-661).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "print('Fish done.')\n",
    "\n",
    "\n",
    "# HORSES\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/horses_listing_scrapes_(all).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "print('Horses done.')\n",
    "\n",
    "\n",
    "# INVERTEBRATES\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/invertebrates_listing_scrapes_(all).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "\n",
    "print('Invertebrates done.')\n",
    "\n",
    "\n",
    "# POULTRY\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/poultry_listing_scrapes_(all).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "\n",
    "print('Poultry done.')\n",
    "\n",
    "\n",
    "# POULTRY\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/poultry_listing_scrapes_(all).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "print('Poultry done.')\n",
    "\n",
    "\n",
    "# RABBITS\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_rabbits_listings/rabbits_listing_scrapes_(0-to-537).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_rabbits_listings/rabbits_listing_scrapes_(537-to-923).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_rabbits_listings/rabbits_listing_scrapes_(923-to-1280).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_rabbits_listings/rabbits_listing_scrapes_(1280-to-1369).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "\n",
    "print('Rabbits done.')\n",
    "\n",
    "\n",
    "\n",
    "# REPTILES\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_reptiles_listings/reptiles_listing_scrapes_(0-to-1584).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/data_reptiles_listings/reptiles_listing_scrapes_(1584-to-2196).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "\n",
    "print('Reptiles done.')\n",
    "\n",
    "\n",
    "\n",
    "# RODENTS\n",
    "all_data = all_data.append(pd.read_csv(f'{path}/rodents_listing_scrapes_(all).csv',\n",
    "                                      index_col = 'Unnamed: 0'))\n",
    "\n",
    "\n",
    "print('Rodents done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 complete. 20161 to go.\n",
      "100 complete. 20111 to go.\n",
      "150 complete. 20061 to go.\n",
      "200 complete. 20011 to go.\n",
      "250 complete. 19961 to go.\n",
      "300 complete. 19911 to go.\n",
      "350 complete. 19861 to go.\n",
      "400 complete. 19811 to go.\n",
      "450 complete. 19761 to go.\n",
      "500 complete. 19711 to go.\n",
      "550 complete. 19661 to go.\n",
      "600 complete. 19611 to go.\n",
      "650 complete. 19561 to go.\n",
      "700 complete. 19511 to go.\n",
      "750 complete. 19461 to go.\n",
      "800 complete. 19411 to go.\n",
      "850 complete. 19361 to go.\n",
      "900 complete. 19311 to go.\n",
      "950 complete. 19261 to go.\n",
      "1000 complete. 19211 to go.\n",
      "1050 complete. 19161 to go.\n",
      "1100 complete. 19111 to go.\n",
      "1150 complete. 19061 to go.\n",
      "1200 complete. 19011 to go.\n",
      "1250 complete. 18961 to go.\n",
      "1300 complete. 18911 to go.\n",
      "1350 complete. 18861 to go.\n",
      "1400 complete. 18811 to go.\n",
      "1450 complete. 18761 to go.\n",
      "1500 complete. 18711 to go.\n",
      "1550 complete. 18661 to go.\n",
      "1600 complete. 18611 to go.\n",
      "1650 complete. 18561 to go.\n",
      "1700 complete. 18511 to go.\n",
      "1750 complete. 18461 to go.\n",
      "1800 complete. 18411 to go.\n",
      "1850 complete. 18361 to go.\n",
      "1900 complete. 18311 to go.\n",
      "1950 complete. 18261 to go.\n",
      "2000 complete. 18211 to go.\n",
      "2050 complete. 18161 to go.\n",
      "2100 complete. 18111 to go.\n",
      "2150 complete. 18061 to go.\n",
      "2200 complete. 18011 to go.\n",
      "2250 complete. 17961 to go.\n",
      "2300 complete. 17911 to go.\n",
      "2350 complete. 17861 to go.\n",
      "2400 complete. 17811 to go.\n",
      "2450 complete. 17761 to go.\n",
      "2500 complete. 17711 to go.\n",
      "2550 complete. 17661 to go.\n",
      "2600 complete. 17611 to go.\n",
      "2650 complete. 17561 to go.\n",
      "2700 complete. 17511 to go.\n",
      "2750 complete. 17461 to go.\n",
      "2800 complete. 17411 to go.\n",
      "2850 complete. 17361 to go.\n",
      "2900 complete. 17311 to go.\n",
      "2950 complete. 17261 to go.\n",
      "3000 complete. 17211 to go.\n",
      "3050 complete. 17161 to go.\n",
      "3100 complete. 17111 to go.\n",
      "3150 complete. 17061 to go.\n",
      "3200 complete. 17011 to go.\n",
      "3250 complete. 16961 to go.\n",
      "3300 complete. 16911 to go.\n",
      "3350 complete. 16861 to go.\n",
      "3400 complete. 16811 to go.\n",
      "3450 complete. 16761 to go.\n",
      "3500 complete. 16711 to go.\n",
      "3550 complete. 16661 to go.\n",
      "3600 complete. 16611 to go.\n",
      "3650 complete. 16561 to go.\n",
      "3700 complete. 16511 to go.\n",
      "3750 complete. 16461 to go.\n",
      "3800 complete. 16411 to go.\n",
      "3850 complete. 16361 to go.\n",
      "3900 complete. 16311 to go.\n",
      "3950 complete. 16261 to go.\n",
      "4000 complete. 16211 to go.\n",
      "4050 complete. 16161 to go.\n",
      "4100 complete. 16111 to go.\n",
      "4150 complete. 16061 to go.\n",
      "4200 complete. 16011 to go.\n",
      "4250 complete. 15961 to go.\n",
      "4300 complete. 15911 to go.\n",
      "4350 complete. 15861 to go.\n",
      "4400 complete. 15811 to go.\n",
      "4450 complete. 15761 to go.\n",
      "4500 complete. 15711 to go.\n",
      "4550 complete. 15661 to go.\n",
      "4600 complete. 15611 to go.\n",
      "4650 complete. 15561 to go.\n",
      "4700 complete. 15511 to go.\n",
      "4750 complete. 15461 to go.\n",
      "4800 complete. 15411 to go.\n",
      "4850 complete. 15361 to go.\n",
      "4900 complete. 15311 to go.\n",
      "4950 complete. 15261 to go.\n",
      "5000 complete. 15211 to go.\n",
      "5050 complete. 15161 to go.\n",
      "5100 complete. 15111 to go.\n",
      "5150 complete. 15061 to go.\n",
      "5200 complete. 15011 to go.\n",
      "5250 complete. 14961 to go.\n",
      "5300 complete. 14911 to go.\n",
      "5350 complete. 14861 to go.\n",
      "5400 complete. 14811 to go.\n",
      "5450 complete. 14761 to go.\n",
      "5500 complete. 14711 to go.\n",
      "5550 complete. 14661 to go.\n",
      "5600 complete. 14611 to go.\n",
      "5650 complete. 14561 to go.\n",
      "5700 complete. 14511 to go.\n",
      "5750 complete. 14461 to go.\n",
      "5800 complete. 14411 to go.\n",
      "5850 complete. 14361 to go.\n",
      "5900 complete. 14311 to go.\n",
      "5950 complete. 14261 to go.\n",
      "6000 complete. 14211 to go.\n",
      "6050 complete. 14161 to go.\n",
      "6100 complete. 14111 to go.\n",
      "6150 complete. 14061 to go.\n",
      "6200 complete. 14011 to go.\n",
      "6250 complete. 13961 to go.\n",
      "6300 complete. 13911 to go.\n",
      "6350 complete. 13861 to go.\n",
      "6400 complete. 13811 to go.\n",
      "6450 complete. 13761 to go.\n",
      "6500 complete. 13711 to go.\n",
      "6550 complete. 13661 to go.\n",
      "6600 complete. 13611 to go.\n",
      "6650 complete. 13561 to go.\n",
      "6700 complete. 13511 to go.\n",
      "6750 complete. 13461 to go.\n",
      "6800 complete. 13411 to go.\n",
      "6850 complete. 13361 to go.\n",
      "6900 complete. 13311 to go.\n",
      "6950 complete. 13261 to go.\n",
      "7000 complete. 13211 to go.\n",
      "7050 complete. 13161 to go.\n",
      "7100 complete. 13111 to go.\n",
      "7150 complete. 13061 to go.\n",
      "7200 complete. 13011 to go.\n",
      "7250 complete. 12961 to go.\n",
      "7300 complete. 12911 to go.\n",
      "7350 complete. 12861 to go.\n",
      "7400 complete. 12811 to go.\n",
      "7450 complete. 12761 to go.\n",
      "7500 complete. 12711 to go.\n",
      "7550 complete. 12661 to go.\n",
      "7600 complete. 12611 to go.\n",
      "7650 complete. 12561 to go.\n",
      "7700 complete. 12511 to go.\n",
      "7750 complete. 12461 to go.\n",
      "7800 complete. 12411 to go.\n",
      "7850 complete. 12361 to go.\n",
      "7900 complete. 12311 to go.\n",
      "7950 complete. 12261 to go.\n",
      "8000 complete. 12211 to go.\n",
      "8050 complete. 12161 to go.\n",
      "8100 complete. 12111 to go.\n",
      "8150 complete. 12061 to go.\n",
      "8200 complete. 12011 to go.\n",
      "8250 complete. 11961 to go.\n",
      "8300 complete. 11911 to go.\n",
      "8350 complete. 11861 to go.\n",
      "8400 complete. 11811 to go.\n",
      "8450 complete. 11761 to go.\n",
      "8500 complete. 11711 to go.\n",
      "8550 complete. 11661 to go.\n",
      "8600 complete. 11611 to go.\n",
      "8650 complete. 11561 to go.\n",
      "8700 complete. 11511 to go.\n",
      "8750 complete. 11461 to go.\n",
      "8800 complete. 11411 to go.\n",
      "8850 complete. 11361 to go.\n",
      "8900 complete. 11311 to go.\n",
      "8950 complete. 11261 to go.\n",
      "9000 complete. 11211 to go.\n",
      "9050 complete. 11161 to go.\n",
      "9100 complete. 11111 to go.\n",
      "9150 complete. 11061 to go.\n",
      "9200 complete. 11011 to go.\n",
      "9250 complete. 10961 to go.\n",
      "9300 complete. 10911 to go.\n",
      "9350 complete. 10861 to go.\n",
      "9400 complete. 10811 to go.\n",
      "9450 complete. 10761 to go.\n",
      "9500 complete. 10711 to go.\n",
      "9550 complete. 10661 to go.\n",
      "9600 complete. 10611 to go.\n",
      "9650 complete. 10561 to go.\n",
      "9700 complete. 10511 to go.\n",
      "9750 complete. 10461 to go.\n",
      "9800 complete. 10411 to go.\n",
      "9850 complete. 10361 to go.\n",
      "9900 complete. 10311 to go.\n",
      "9950 complete. 10261 to go.\n",
      "10000 complete. 10211 to go.\n",
      "10050 complete. 10161 to go.\n",
      "10100 complete. 10111 to go.\n",
      "10150 complete. 10061 to go.\n",
      "10200 complete. 10011 to go.\n",
      "10250 complete. 9961 to go.\n",
      "10300 complete. 9911 to go.\n",
      "10350 complete. 9861 to go.\n",
      "10400 complete. 9811 to go.\n",
      "10450 complete. 9761 to go.\n",
      "10500 complete. 9711 to go.\n",
      "10550 complete. 9661 to go.\n",
      "10600 complete. 9611 to go.\n",
      "10650 complete. 9561 to go.\n",
      "10700 complete. 9511 to go.\n",
      "10750 complete. 9461 to go.\n",
      "10800 complete. 9411 to go.\n",
      "10850 complete. 9361 to go.\n",
      "10900 complete. 9311 to go.\n",
      "10950 complete. 9261 to go.\n",
      "11000 complete. 9211 to go.\n",
      "11050 complete. 9161 to go.\n",
      "11100 complete. 9111 to go.\n",
      "11150 complete. 9061 to go.\n",
      "11200 complete. 9011 to go.\n",
      "11250 complete. 8961 to go.\n",
      "11300 complete. 8911 to go.\n",
      "11350 complete. 8861 to go.\n",
      "11400 complete. 8811 to go.\n",
      "11450 complete. 8761 to go.\n",
      "11500 complete. 8711 to go.\n",
      "11550 complete. 8661 to go.\n",
      "11600 complete. 8611 to go.\n",
      "11650 complete. 8561 to go.\n",
      "11700 complete. 8511 to go.\n",
      "11750 complete. 8461 to go.\n",
      "11800 complete. 8411 to go.\n",
      "11850 complete. 8361 to go.\n",
      "11900 complete. 8311 to go.\n",
      "11950 complete. 8261 to go.\n",
      "12000 complete. 8211 to go.\n",
      "12050 complete. 8161 to go.\n",
      "12100 complete. 8111 to go.\n",
      "12150 complete. 8061 to go.\n",
      "12200 complete. 8011 to go.\n",
      "12250 complete. 7961 to go.\n",
      "12300 complete. 7911 to go.\n",
      "12350 complete. 7861 to go.\n",
      "12400 complete. 7811 to go.\n",
      "12450 complete. 7761 to go.\n",
      "12500 complete. 7711 to go.\n",
      "12550 complete. 7661 to go.\n",
      "12600 complete. 7611 to go.\n",
      "12650 complete. 7561 to go.\n",
      "12700 complete. 7511 to go.\n",
      "12750 complete. 7461 to go.\n",
      "12800 complete. 7411 to go.\n",
      "12850 complete. 7361 to go.\n",
      "12900 complete. 7311 to go.\n",
      "12950 complete. 7261 to go.\n",
      "13000 complete. 7211 to go.\n",
      "13050 complete. 7161 to go.\n",
      "13100 complete. 7111 to go.\n",
      "13150 complete. 7061 to go.\n",
      "13200 complete. 7011 to go.\n",
      "13250 complete. 6961 to go.\n",
      "13300 complete. 6911 to go.\n",
      "13350 complete. 6861 to go.\n",
      "13400 complete. 6811 to go.\n",
      "13450 complete. 6761 to go.\n",
      "13500 complete. 6711 to go.\n",
      "13550 complete. 6661 to go.\n",
      "13600 complete. 6611 to go.\n",
      "13650 complete. 6561 to go.\n",
      "13700 complete. 6511 to go.\n",
      "13750 complete. 6461 to go.\n",
      "13800 complete. 6411 to go.\n",
      "13850 complete. 6361 to go.\n",
      "13900 complete. 6311 to go.\n",
      "13950 complete. 6261 to go.\n",
      "14000 complete. 6211 to go.\n",
      "14050 complete. 6161 to go.\n",
      "14100 complete. 6111 to go.\n",
      "14150 complete. 6061 to go.\n",
      "14200 complete. 6011 to go.\n",
      "14250 complete. 5961 to go.\n",
      "14300 complete. 5911 to go.\n",
      "14350 complete. 5861 to go.\n",
      "14400 complete. 5811 to go.\n",
      "14450 complete. 5761 to go.\n",
      "14500 complete. 5711 to go.\n",
      "14550 complete. 5661 to go.\n",
      "14600 complete. 5611 to go.\n",
      "14650 complete. 5561 to go.\n",
      "14700 complete. 5511 to go.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14750 complete. 5461 to go.\n",
      "14800 complete. 5411 to go.\n",
      "14850 complete. 5361 to go.\n",
      "14900 complete. 5311 to go.\n",
      "14950 complete. 5261 to go.\n",
      "15000 complete. 5211 to go.\n",
      "15050 complete. 5161 to go.\n",
      "15100 complete. 5111 to go.\n",
      "15150 complete. 5061 to go.\n",
      "15200 complete. 5011 to go.\n",
      "15250 complete. 4961 to go.\n",
      "15300 complete. 4911 to go.\n",
      "15350 complete. 4861 to go.\n",
      "15400 complete. 4811 to go.\n",
      "15450 complete. 4761 to go.\n",
      "15500 complete. 4711 to go.\n",
      "15550 complete. 4661 to go.\n",
      "15600 complete. 4611 to go.\n",
      "15650 complete. 4561 to go.\n",
      "15700 complete. 4511 to go.\n",
      "15750 complete. 4461 to go.\n",
      "15800 complete. 4411 to go.\n",
      "15850 complete. 4361 to go.\n",
      "15900 complete. 4311 to go.\n",
      "15950 complete. 4261 to go.\n",
      "16000 complete. 4211 to go.\n",
      "16050 complete. 4161 to go.\n",
      "16100 complete. 4111 to go.\n",
      "16150 complete. 4061 to go.\n",
      "16200 complete. 4011 to go.\n",
      "16250 complete. 3961 to go.\n",
      "16300 complete. 3911 to go.\n",
      "16350 complete. 3861 to go.\n",
      "16400 complete. 3811 to go.\n",
      "16450 complete. 3761 to go.\n",
      "16500 complete. 3711 to go.\n",
      "16550 complete. 3661 to go.\n",
      "16600 complete. 3611 to go.\n",
      "16650 complete. 3561 to go.\n",
      "16700 complete. 3511 to go.\n",
      "16750 complete. 3461 to go.\n",
      "16800 complete. 3411 to go.\n",
      "16850 complete. 3361 to go.\n",
      "16900 complete. 3311 to go.\n",
      "16950 complete. 3261 to go.\n",
      "17000 complete. 3211 to go.\n",
      "17050 complete. 3161 to go.\n",
      "17100 complete. 3111 to go.\n",
      "17150 complete. 3061 to go.\n",
      "17200 complete. 3011 to go.\n",
      "17250 complete. 2961 to go.\n",
      "17300 complete. 2911 to go.\n",
      "17350 complete. 2861 to go.\n",
      "17400 complete. 2811 to go.\n",
      "17450 complete. 2761 to go.\n",
      "17500 complete. 2711 to go.\n",
      "17550 complete. 2661 to go.\n",
      "17600 complete. 2611 to go.\n",
      "17650 complete. 2561 to go.\n",
      "17700 complete. 2511 to go.\n",
      "17750 complete. 2461 to go.\n",
      "17800 complete. 2411 to go.\n",
      "17850 complete. 2361 to go.\n",
      "17900 complete. 2311 to go.\n",
      "17950 complete. 2261 to go.\n",
      "18000 complete. 2211 to go.\n",
      "18050 complete. 2161 to go.\n",
      "18100 complete. 2111 to go.\n",
      "18150 complete. 2061 to go.\n",
      "18200 complete. 2011 to go.\n",
      "18250 complete. 1961 to go.\n",
      "18300 complete. 1911 to go.\n",
      "18350 complete. 1861 to go.\n",
      "18400 complete. 1811 to go.\n",
      "18450 complete. 1761 to go.\n",
      "18500 complete. 1711 to go.\n",
      "18550 complete. 1661 to go.\n",
      "18600 complete. 1611 to go.\n",
      "18650 complete. 1561 to go.\n",
      "18700 complete. 1511 to go.\n",
      "18750 complete. 1461 to go.\n",
      "18800 complete. 1411 to go.\n",
      "18850 complete. 1361 to go.\n",
      "18900 complete. 1311 to go.\n",
      "18950 complete. 1261 to go.\n",
      "19000 complete. 1211 to go.\n",
      "19050 complete. 1161 to go.\n",
      "19100 complete. 1111 to go.\n",
      "19150 complete. 1061 to go.\n",
      "19200 complete. 1011 to go.\n",
      "19250 complete. 961 to go.\n",
      "19300 complete. 911 to go.\n",
      "19350 complete. 861 to go.\n",
      "19400 complete. 811 to go.\n",
      "19450 complete. 761 to go.\n",
      "19500 complete. 711 to go.\n",
      "19550 complete. 661 to go.\n",
      "19600 complete. 611 to go.\n",
      "19650 complete. 561 to go.\n",
      "19700 complete. 511 to go.\n",
      "19750 complete. 461 to go.\n",
      "19800 complete. 411 to go.\n",
      "19850 complete. 361 to go.\n",
      "19900 complete. 311 to go.\n",
      "19950 complete. 261 to go.\n",
      "20000 complete. 211 to go.\n",
      "20050 complete. 161 to go.\n",
      "20100 complete. 111 to go.\n",
      "20150 complete. 61 to go.\n",
      "20200 complete. 11 to go.\n",
      "20 failed. Done.\n"
     ]
    }
   ],
   "source": [
    "# extracting dataset from htmls\n",
    "\n",
    "pets_data = []\n",
    "\n",
    "n = 0\n",
    "el = 0\n",
    "\n",
    "for pet in all_data['URLs']:\n",
    "    el += 1\n",
    "    if el % 50 == 0:\n",
    "        print(f'{el} complete. {len(all_data[\"URLs\"]) - el} to go.')\n",
    "    try:\n",
    "        pets_data.append(extract_data(pet))\n",
    "    except:\n",
    "        n += 1\n",
    "        pass    \n",
    "print(f'{n} failed. Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pets_df = pd.DataFrame.from_dict(pets_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718 duplicate rows dropped\n"
     ]
    }
   ],
   "source": [
    "# removing duplicate rows\n",
    "print(f'{pets_df.shape[0] - pets_df.drop_duplicates().shape[0]} duplicate rows dropped') \n",
    "pets_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'price', 'url', 'seller_type', 'seller_name', 'Phone', 'Email',\n",
      "       'Facebook', 'Google', 'n_images', 'category', 'Adv. ID',\n",
      "       'Adv. Location', 'Advert Type', 'Advertiser', 'Breed', 'Pet Age: ',\n",
      "       'Pet Colour', 'Sex', 'description', 'Health Checked', 'Is Microchipped',\n",
      "       'Is Neutered', 'Is Vaccinated', 'Is Worm Treated', 'Pet Available',\n",
      "       'Pets in litter', 'Registered', 'Is advertiser the orig. breeder',\n",
      "       'Is KC Registered', 'Pet Viewable with Mother', 'Birth Year',\n",
      "       'Category 1', 'Category 2', 'Gender', 'Height', 'Origin',\n",
      "       'Level Jumping', 'Level Dressage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# checking columns\n",
    "print(pets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'price', 'url', 'seller_type', 'seller_name', 'phone_verified',\n",
      "       'email_verified', 'facebook_verified', 'google_verified', 'n_images',\n",
      "       'category', 'advert_id', 'advert_location', 'advert_type',\n",
      "       'advertiser_type', 'breed', 'pet_age', 'pet_colour', 'pet_sex',\n",
      "       'description', 'health_checked', 'microchipped', 'neutered',\n",
      "       'vaccinated', 'worm_treated', 'pet_available', 'pets_in_litter',\n",
      "       'registered', 'original_breeder', 'kc_registered',\n",
      "       'viewable_with_mother', 'birth_year', 'category_1', 'category_2',\n",
      "       'gender', 'height', 'origin', 'level_jumping', 'level_dressage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cleaning column names\n",
    "\n",
    "pets_df.columns = ['title', \n",
    " 'price', \n",
    " 'url', \n",
    " 'seller_type', \n",
    " 'seller_name', \n",
    " 'phone_verified', \n",
    " 'email_verified',\n",
    " 'facebook_verified', \n",
    " 'google_verified', \n",
    " 'n_images', \n",
    " 'category',\n",
    " 'advert_id', \n",
    " 'advert_location',\n",
    " 'advert_type', \n",
    " 'advertiser_type', \n",
    " 'breed', \n",
    " 'pet_age', \n",
    " 'pet_colour', \n",
    " 'pet_sex',\n",
    " 'description',\n",
    " 'health_checked',\n",
    " 'microchipped',\n",
    " 'neutered',\n",
    " 'vaccinated',\n",
    " 'worm_treated',\n",
    " 'pet_available',\n",
    " 'pets_in_litter',\n",
    " 'registered',\n",
    " 'original_breeder',\n",
    " 'kc_registered',\n",
    " 'viewable_with_mother',\n",
    " 'birth_year',\n",
    " 'category_1',\n",
    " 'category_2',\n",
    " 'gender',\n",
    " 'height',\n",
    " 'origin',\n",
    " 'level_jumping',\n",
    " 'level_dressage']\n",
    "\n",
    "print(pets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                    object\n",
       "price                    object\n",
       "url                      object\n",
       "seller_type              object\n",
       "seller_name              object\n",
       "phone_verified          float64\n",
       "email_verified          float64\n",
       "facebook_verified       float64\n",
       "google_verified         float64\n",
       "n_images                  int64\n",
       "category                 object\n",
       "advert_id                object\n",
       "advert_location          object\n",
       "advert_type              object\n",
       "advertiser_type          object\n",
       "breed                    object\n",
       "pet_age                  object\n",
       "pet_colour               object\n",
       "pet_sex                  object\n",
       "description              object\n",
       "health_checked           object\n",
       "microchipped             object\n",
       "neutered                 object\n",
       "vaccinated               object\n",
       "worm_treated             object\n",
       "pet_available            object\n",
       "pets_in_litter           object\n",
       "registered               object\n",
       "original_breeder         object\n",
       "kc_registered            object\n",
       "viewable_with_mother     object\n",
       "birth_year               object\n",
       "category_1               object\n",
       "category_2               object\n",
       "gender                   object\n",
       "height                   object\n",
       "origin                   object\n",
       "level_jumping            object\n",
       "level_dressage           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# converting price dtype to float\n",
    "pets_df.price = pets_df.price.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dropping advert type, as all values are the same\n",
    "pets_df.drop(columns = 'advert_type', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 9475 of the sellers have unique names\n",
    "sum(pets_df['seller_name'].value_counts()==1)\n",
    "\n",
    "# 3219 of the seller names appear more than once\n",
    "sum(pets_df['seller_name'].value_counts()>1)\n",
    "\n",
    "# of the sellers who's names appear more than once, 1153 are organizations\n",
    "sum(pets_df[pets_df['seller_type'] == 'Organization']['seller_name'].value_counts()>1)\n",
    "\n",
    "# I'm going to drop the seller_name column and replace it with a continuous numeric column indicating the \n",
    "# number of times that seller's name appeared in the dataset. \n",
    "seller_name_n_occurances = dict(pets_df['seller_name'].value_counts())\n",
    "pets_df['seller_n_adverts'] = [seller_name_n_occurances[i] for i in pets_df['seller_name']]\n",
    "pets_df.drop(columns = 'seller_name', inplace = True)\n",
    "\n",
    "# Roughly 2/3rds of the sellers who's names appear more than once are individuals, it is likely that several \n",
    "# of these are multiple individuals with similar names (e.g. John S.). I will explore this relationship\n",
    "# during EDA and will perform additional cleaning if it seems necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London         1116\n",
       "Birmingham      454\n",
       "Manchester      386\n",
       "Nottingham      251\n",
       "Doncaster       218\n",
       "               ... \n",
       "Corsham           1\n",
       "Lifton            1\n",
       "IsleofLewis       1\n",
       "Keith             1\n",
       "Bures             1\n",
       "Name: advert_location, Length: 1168, dtype: int64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6653 unique locations\n",
    "pets_df['advert_location'].value_counts()\n",
    "\n",
    "# converting all values to strings\n",
    "pets_df['advert_location'] = pets_df['advert_location'].astype(str)\n",
    "\n",
    "# taking only the last elemnt of each location\n",
    "pets_df['advert_location'] = [i.split(',')[-1].replace(' ', '') for i in pets_df['advert_location']]\n",
    "\n",
    "# 1168 unique locations\n",
    "pets_df['advert_location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# the seller_type and advertiser_type columns contain similar information. Advertiser type has more details\n",
    "# on the types of organisations, but includes some NaNs. I will combine these columns.\n",
    "\n",
    "# no 'Organization' has advertiser_type == 'Individual', there are 68 NaNs.\n",
    "pets_df[pets_df['seller_type'] == 'Organization']['advertiser_type'].value_counts(dropna = False)\n",
    "\n",
    "# every 'Person' has advertiser_type == 'Individual', except 92 NaNs\n",
    "pets_df[pets_df['seller_type'] == 'Person']['advertiser_type'].value_counts(dropna = False)\n",
    "\n",
    "# Inferring any row with seller_type == 'Person' should have advertiser_type == 'Individual' & replacing NaNs\n",
    "pets_df.loc[pets_df['seller_type'] == 'Person','advertiser_type'] = 'Individual'\n",
    "\n",
    "# Looking at rows with seller_type == 'Organization' & advertiser_type == NaN\n",
    "pets_df[(pets_df['seller_type'] == 'Organization') & (pets_df['advertiser_type'].isna())]\n",
    "\n",
    "# These adverts all have similar/generic titles (e.g. \"rabbits for sale\"), NaNs in most columns\n",
    "# and are not verified by any of the 4 verification methods. I suspect they're fake ads and so will drop them.\n",
    "pets_df = pets_df[pets_df['advertiser_type'].notna()]\n",
    "\n",
    "# advertiser_type now contains all information in seller_type (plus extra detail), dropping seller_type\n",
    "pets_df.drop(columns = 'seller_type', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 388 unique values for breed\n",
    "pets_df.breed.value_counts()\n",
    "\n",
    "# 92 NaNs\n",
    "sum(pets_df.breed.isna())\n",
    "pets_df[pets_df.breed.isna()]\n",
    "\n",
    "# these adverts seem similar to the ones I removed in the previous cell. I.e. mostly NaNs, unverified, generic\n",
    "# names, etc. Dropping them.\n",
    "pets_df = pets_df[pets_df.breed.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pet_age and birth_year contain similar information, but the latter is horse specific. I'll combine them.\n",
    "\n",
    "# all rows with birth_year != NaN are horses\n",
    "pets_df[pets_df.birth_year.notna()]['category'].value_counts()\n",
    "\n",
    "# no horse rows have NaNs for birth_year\n",
    "len(pets_df[pets_df['category'] == 'Horses'])\n",
    "\n",
    "# Horses' age in years can be approximated from their birth_year\n",
    "pets_df.loc[pets_df['category'] == 'Horses','pet_age'] = (2023 - pets_df[pets_df['category'] == 'Horses']['birth_year'].astype(int)).astype(str)+' years'\n",
    "\n",
    "# birth_year can now be dropped\n",
    "pets_df.drop(columns = 'birth_year', inplace = True)\n",
    "\n",
    "# 34 rows remain with NaN for pet_age. I'll drop them.\n",
    "pets_df['pet_age'].isna().sum()\n",
    "pets_df = pets_df[pets_df['pet_age'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "#dt = datetime.datetime.strptime(str_td, \"%H:%M:%S\")\n",
    "pets_age_in_days = []\n",
    "for row in [i.split(',') for i in pets_df['pet_age'].astype(str)]:\n",
    "    num_days = 0\n",
    "    for el in row:\n",
    "        try:\n",
    "            if el == 'Just Born Today':\n",
    "                pass\n",
    "            elif 'NaN' in el: # some rows have 'NaN years' / 'NaN months'\n",
    "                num_days = np.nan\n",
    "            elif 'year' in el:\n",
    "                num_days += (int(re.findall('\\d+', el)[0]) * 365)\n",
    "            elif 'month' in el:\n",
    "                # 30.436875 is the mean month length in the gregorian calendar\n",
    "                num_days += (int(re.findall('\\d+', el)[0]) * 30.436875)\n",
    "            elif 'week' in el:\n",
    "                num_days += (int(re.findall('\\d+', el)[0]) * 7)\n",
    "            elif 'day' in el:\n",
    "                num_days += int(re.findall('\\d+', el)[0])\n",
    "        except Exception as e:\n",
    "              print(el)\n",
    "    pets_age_in_days.append(num_days)\n",
    "    \n",
    "pets_df['pets_age_in_days'] = pets_age_in_days\n",
    "\n",
    "# after converting all ages to days, 3 missing values remain, which I'll drop\n",
    "pets_df[pets_df['pets_age_in_days'].isna()]\n",
    "pets_df = pets_df[pets_df['pets_age_in_days'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# about half of the rows have NaNs for pet_available (the date from which the pet is available for collection)\n",
    "pets_df['pet_available'].isna().sum()\n",
    "\n",
    "# Given this and given that this is unlikely to be a good predictor of price, I'm going to drop the column.\n",
    "pets_df = pets_df.drop(columns = 'pet_available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 'registered' is cat specific and indicates if the cat is regisitered with one of 3 ownership clubs\n",
    "# e.g. The Governing Council of the Cat Fancy (no, seriously). 'kc_registered' indicates whether a dog is \n",
    "# registered with the UK Kennel Club. These two colums can be combined. Later I'll create interaction terms\n",
    "# with the pet catergories.\n",
    "\n",
    "# for dogs, we have yes and no values and no NaNs\n",
    "pets_df[pets_df['category'] == 'Dogs']['kc_registered'].value_counts(dropna = False)\n",
    "\n",
    "# for cats, we have 2344 NaNs and either 'TICA', 'GCCF', 'FIFe', or some combination of them\n",
    "pets_df[pets_df['category'] == 'Cats']['registered'].value_counts(dropna = False)\n",
    "\n",
    "# If a cat is registered with any club, I will encode this as 1\n",
    "pets_df.loc[(pets_df['category'] == 'Cats') & (pets_df['registered'].notna()), 'registered'] = 1\n",
    "\n",
    "# I will assume that cats with NaNs for registered are not registered with any club\n",
    "pets_df.loc[(pets_df['category'] == 'Cats') & (pets_df['registered'].isna()), 'registered'] = 0\n",
    "\n",
    "# for dogs, I'll move the kc_registered values over to registered\n",
    "pets_df.loc[(pets_df['category'] == 'Dogs') & (pets_df['kc_registered'] == 'yes'), 'registered'] = 1\n",
    "pets_df.loc[(pets_df['category'] == 'Dogs') & (pets_df['kc_registered'] == 'no'), 'registered'] = 0\n",
    "\n",
    "# kc_registered can now be dropped\n",
    "pets_df.drop(columns = 'kc_registered', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pets in litter takes the form of 'n males / n females'. Needs to be cleaned into two continuous numeric \n",
    "# columns. \n",
    "\n",
    "males_in_litter = []\n",
    "females_in_litter = []\n",
    "\n",
    "for row in pets_df[pets_df['pets_in_litter'].notna()]['pets_in_litter']:\n",
    "    \n",
    "    males_in_cur_litter = 0\n",
    "    females_in_cur_litter = 0\n",
    "\n",
    "    els = row.split('/')\n",
    "    for el in els[:2]:\n",
    "    \n",
    "        if 'female' in el:\n",
    "            females_in_cur_litter += int(re.findall('\\d+', el)[0])\n",
    "        \n",
    "        elif 'male' in el:\n",
    "            males_in_cur_litter += int(re.findall('\\d+', el)[0])\n",
    "    \n",
    "    males_in_litter.append(males_in_cur_litter)\n",
    "    females_in_litter.append(females_in_cur_litter)\n",
    "    \n",
    "# adding new columns\n",
    "pets_df.loc[pets_df['pets_in_litter'].notna(), 'males_in_litter'] = males_in_litter\n",
    "pets_df.loc[pets_df['pets_in_litter'].notna(), 'females_in_litter'] = females_in_litter\n",
    "\n",
    "# dropping pets in litter\n",
    "pets_df.drop(columns = 'pets_in_litter', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The columns 'pet_sex', 'gender' and 'neutered' have some over lap and need some specific processing. 'pet_sex' has three levels (male, female and mixed), 'gender' is specific to horse listings and also has three levels (mare, gelding and stallion). 'neutered' only has two levels, but a gelding is an neutered male horse, but the horse rows all have NaNs for the 'neutered' column. I will sort these columns so that the information stored in 'gender' is in the 'pet_sex' and 'neutered' columns, and 'gender' can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if gender == gelding, neutered == yes, pet_sex == male\n",
    "pets_df.loc[pets_df['gender'] == 'Gelding', 'neutered'] = 'yes'\n",
    "pets_df.loc[pets_df['gender' ]== 'Gelding', 'pet_sex'] = 'Male'\n",
    "\n",
    "# if gender == stallion, neutered == n, pet_sex == male\n",
    "pets_df.loc[pets_df['gender'] == 'Stallion', 'neutered'] = 'no'\n",
    "pets_df.loc[pets_df['gender' ]== 'Stallion', 'pet_sex'] = 'Male'\n",
    "\n",
    "# spaying a mare is extremely rare as it a dangerous operation. Its typically only done in the UK as a \n",
    "# life-saving proceedure. As such, I will assume all listed mares have not been spayed.\n",
    "pets_df.loc[pets_df['gender'] == 'Mare', 'neutered'] = 'no'\n",
    "pets_df.loc[pets_df['gender' ]== 'Mare', 'pet_sex'] = 'Female'\n",
    "\n",
    "# dropping gender\n",
    "pets_df.drop(columns = 'gender', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Having disentangled gender and pet_sex, there is still some semantic overlap between the pet_sex and fe/males_in_litter. Specifically, columns with non-NaN values for pet_sex all have NaNs for fe/males_in_litter. Where the litter is all male or all female, pet_sex can be updated to match that. Where there are both, pet_sex can be updated to mixed. \n",
    "\n",
    "I still want to keep both columns as fe/males_in_litter indicates a) that the pets are infants and b) the number of either gender, which is absent from pet_sex. However, I cant just drop pet_sex, as some of the pets are adult animals and so would have a fe/males_in_litter value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mixed     3256\n",
       "Male      2302\n",
       "Female    1638\n",
       "Name: pet_sex, dtype: int64"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df['pet_sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pets_df.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/data/pets4homes_data_(16-01-23)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/yfr_960x69zdtf98dwdj7s6r0000gn/T/ipykernel_1673/221125597.py:1: DtypeWarning: Columns (15,18,19,20,21,22,24,25,26,27,28,29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pets_df = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/data/pets4homes_data_(16-01-23)',\n"
     ]
    }
   ],
   "source": [
    "pets_df = pd.read_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/data/pets4homes_data_(16-01-23)',\n",
    "                     index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>url</th>\n",
       "      <th>phone_verified</th>\n",
       "      <th>email_verified</th>\n",
       "      <th>facebook_verified</th>\n",
       "      <th>google_verified</th>\n",
       "      <th>n_images</th>\n",
       "      <th>category</th>\n",
       "      <th>advert_id</th>\n",
       "      <th>advert_location</th>\n",
       "      <th>advertiser_type</th>\n",
       "      <th>breed</th>\n",
       "      <th>pet_age</th>\n",
       "      <th>pet_colour</th>\n",
       "      <th>pet_sex</th>\n",
       "      <th>description</th>\n",
       "      <th>health_checked</th>\n",
       "      <th>microchipped</th>\n",
       "      <th>neutered</th>\n",
       "      <th>vaccinated</th>\n",
       "      <th>worm_treated</th>\n",
       "      <th>registered</th>\n",
       "      <th>original_breeder</th>\n",
       "      <th>viewable_with_mother</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>height</th>\n",
       "      <th>origin</th>\n",
       "      <th>level_jumping</th>\n",
       "      <th>level_dressage</th>\n",
       "      <th>seller_n_adverts</th>\n",
       "      <th>pets_age_in_days</th>\n",
       "      <th>males_in_litter</th>\n",
       "      <th>females_in_litter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budgies for sale</td>\n",
       "      <td>20.0</td>\n",
       "      <td>/classifieds/vpqtzqc0i-budgies-for-sale-middle...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Birds</td>\n",
       "      <td>VpQTZqc0I</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>Breeder</td>\n",
       "      <td>Budgerigars</td>\n",
       "      <td>10 months, 3 days</td>\n",
       "      <td>Blue, Green, Yellow</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Exhibition Budgies for sale\\n\\nBoth male and f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>307.36875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ringneck</td>\n",
       "      <td>120.0</td>\n",
       "      <td>/classifieds/khxbn9dk9-ringneck-witney/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Birds</td>\n",
       "      <td>khxBn9dK9</td>\n",
       "      <td>Witney</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Ringnecks</td>\n",
       "      <td>3 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>A honest post please read fully. \\nIndie is my...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1095.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kakarekis</td>\n",
       "      <td>35.0</td>\n",
       "      <td>/classifieds/m4uz4ww-a-kakarekis-northwich/</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Birds</td>\n",
       "      <td>m4uZ4ww-A</td>\n",
       "      <td>Northwich</td>\n",
       "      <td>Breeder</td>\n",
       "      <td>Parakeets</td>\n",
       "      <td>8 months, 26 days</td>\n",
       "      <td>Green</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>beautiful this years young baby’s parent reare...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>269.49500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baby / adult budgies for sale £ 15 each  2 for...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>/classifieds/ohjzun2lp-baby-adult-budgies-for-...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Birds</td>\n",
       "      <td>OHjzUN2Lp</td>\n",
       "      <td>WalthamAbbey</td>\n",
       "      <td>Breeder</td>\n",
       "      <td>Budgerigars</td>\n",
       "      <td>3 days</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Baby and adult budgies for sale\\n£15 each \\n2 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beautiful friendly white capped Pionus parrots</td>\n",
       "      <td>675.0</td>\n",
       "      <td>/classifieds/5npb4stu6-beautiful-friendly-whit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Birds</td>\n",
       "      <td>5nPB4sTu6</td>\n",
       "      <td>Ilford</td>\n",
       "      <td>Breeder</td>\n",
       "      <td>Parrots</td>\n",
       "      <td>15 weeks</td>\n",
       "      <td>Green</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Hand reared white capped pionus. Very friendly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  price  \\\n",
       "0                                 Budgies for sale     20.0   \n",
       "1                                         Ringneck    120.0   \n",
       "2                                         kakarekis    35.0   \n",
       "3  Baby / adult budgies for sale £ 15 each  2 for...   15.0   \n",
       "4   Beautiful friendly white capped Pionus parrots    675.0   \n",
       "\n",
       "                                                 url  phone_verified  \\\n",
       "0  /classifieds/vpqtzqc0i-budgies-for-sale-middle...             1.0   \n",
       "1            /classifieds/khxbn9dk9-ringneck-witney/             1.0   \n",
       "2        /classifieds/m4uz4ww-a-kakarekis-northwich/             1.0   \n",
       "3  /classifieds/ohjzun2lp-baby-adult-budgies-for-...             1.0   \n",
       "4  /classifieds/5npb4stu6-beautiful-friendly-whit...             1.0   \n",
       "\n",
       "   email_verified  facebook_verified  google_verified  n_images category  \\\n",
       "0             1.0                0.0              0.0         9    Birds   \n",
       "1             1.0                0.0              1.0         3    Birds   \n",
       "2             1.0                0.0              0.0         2    Birds   \n",
       "3             1.0                0.0              0.0         7    Birds   \n",
       "4             1.0                0.0              1.0         7    Birds   \n",
       "\n",
       "   advert_id advert_location advertiser_type        breed            pet_age  \\\n",
       "0  VpQTZqc0I   Middlesbrough         Breeder  Budgerigars  10 months, 3 days   \n",
       "1  khxBn9dK9          Witney      Individual    Ringnecks            3 years   \n",
       "2  m4uZ4ww-A       Northwich         Breeder    Parakeets  8 months, 26 days   \n",
       "3  OHjzUN2Lp    WalthamAbbey         Breeder  Budgerigars             3 days   \n",
       "4  5nPB4sTu6          Ilford         Breeder      Parrots           15 weeks   \n",
       "\n",
       "            pet_colour pet_sex  \\\n",
       "0  Blue, Green, Yellow   Mixed   \n",
       "1                  NaN  Female   \n",
       "2                Green   Mixed   \n",
       "3                  NaN   Mixed   \n",
       "4                Green   Mixed   \n",
       "\n",
       "                                         description health_checked  \\\n",
       "0  Exhibition Budgies for sale\\n\\nBoth male and f...            NaN   \n",
       "1  A honest post please read fully. \\nIndie is my...            NaN   \n",
       "2  beautiful this years young baby’s parent reare...            NaN   \n",
       "3  Baby and adult budgies for sale\\n£15 each \\n2 ...            NaN   \n",
       "4  Hand reared white capped pionus. Very friendly...            NaN   \n",
       "\n",
       "  microchipped neutered vaccinated worm_treated  registered original_breeder  \\\n",
       "0          NaN      NaN        NaN          NaN         NaN              NaN   \n",
       "1          NaN      NaN        NaN          NaN         NaN              NaN   \n",
       "2          NaN      NaN        NaN          NaN         NaN              NaN   \n",
       "3          NaN      NaN        NaN          NaN         NaN              NaN   \n",
       "4          NaN      NaN        NaN          NaN         NaN              NaN   \n",
       "\n",
       "  viewable_with_mother category_1 category_2 height origin level_jumping  \\\n",
       "0                  NaN        NaN        NaN    NaN    NaN           NaN   \n",
       "1                  NaN        NaN        NaN    NaN    NaN           NaN   \n",
       "2                  NaN        NaN        NaN    NaN    NaN           NaN   \n",
       "3                  NaN        NaN        NaN    NaN    NaN           NaN   \n",
       "4                  NaN        NaN        NaN    NaN    NaN           NaN   \n",
       "\n",
       "  level_dressage  seller_n_adverts  pets_age_in_days  males_in_litter  \\\n",
       "0            NaN                 3         307.36875              NaN   \n",
       "1            NaN                 6        1095.00000              NaN   \n",
       "2            NaN                 1         269.49500              NaN   \n",
       "3            NaN                 3           3.00000              NaN   \n",
       "4            NaN                 4         105.00000              NaN   \n",
       "\n",
       "   females_in_litter  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mixed     9687\n",
       "Male      4183\n",
       "Female    3615\n",
       "NaN       1791\n",
       "Name: pet_sex, dtype: int64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are all NaN\n",
    "pets_df[pets_df['pet_sex'].notna()]['males_in_litter'].value_counts(dropna = False)\n",
    "pets_df[pets_df['pet_sex'].notna()]['females_in_litter'].value_counts(dropna = False)\n",
    "\n",
    "# These are also all NaN\n",
    "pets_df[pets_df['males_in_litter'].notna()]['pet_sex'].value_counts(dropna = False)\n",
    "pets_df[pets_df['females_in_litter'].notna()]['pet_sex'].value_counts(dropna = False)\n",
    "\n",
    "# These can be updated to 'Mixed'\n",
    "pets_df.loc[(pets_df['pet_sex'].isna()) & (pets_df['males_in_litter'] > 0) & (pets_df['females_in_litter'] > 0),['pet_sex']] = 'Mixed'\n",
    "\n",
    "# These can be updated to 'Male'\n",
    "pets_df.loc[(pets_df['pet_sex'].isna()) & (pets_df['males_in_litter'] > 0) & (pets_df['females_in_litter'] == 0),['pet_sex']] = 'Male'\n",
    "\n",
    "# These can be updated to 'Female'\n",
    "pets_df.loc[(pets_df['pet_sex'].isna()) & (pets_df['males_in_litter'] == 0) & (pets_df['females_in_litter'] > 0),['pet_sex']] = 'Female'\n",
    "\n",
    "# This leaves 1791 NaNs\n",
    "pets_df['pet_sex'].value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                       0\n",
       "price                       0\n",
       "url                         0\n",
       "phone_verified              0\n",
       "email_verified              0\n",
       "facebook_verified           0\n",
       "google_verified             0\n",
       "n_images                    0\n",
       "category                    0\n",
       "advert_id                   0\n",
       "advert_location             0\n",
       "advertiser_type             0\n",
       "breed                       0\n",
       "pet_age                     0\n",
       "pet_colour              11138\n",
       "pet_sex                  1791\n",
       "description                 0\n",
       "health_checked           7863\n",
       "microchipped             6524\n",
       "neutered                 6269\n",
       "vaccinated               6524\n",
       "worm_treated             6599\n",
       "registered               7861\n",
       "original_breeder        13770\n",
       "viewable_with_mother    11451\n",
       "category_1              19021\n",
       "category_2              19072\n",
       "height                  19026\n",
       "origin                  19021\n",
       "level_jumping           19263\n",
       "level_dressage          19268\n",
       "seller_n_adverts            0\n",
       "pets_age_in_days            0\n",
       "males_in_litter          8987\n",
       "females_in_litter        8987\n",
       "dtype: int64"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I still have a large number of missing values for several columns. This will be due to one of two reasons. 1. some aspect of the scrape/data extraction steps failed for those instances. 2. Those columns specify information which is not applicable to certain catergories of animals. An example of 2 is level_dressage, which is specific to horses. \n",
    "\n",
    "I need to determine which NaNs belong to which category. The NaNs in catergory 1 need to be cleaned/imputed/dropped. The NaNs in category 2 can replaced by a placeholder value indicating that this category is not relevant for that animal type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>url</th>\n",
       "      <th>phone_verified</th>\n",
       "      <th>email_verified</th>\n",
       "      <th>facebook_verified</th>\n",
       "      <th>google_verified</th>\n",
       "      <th>n_images</th>\n",
       "      <th>category</th>\n",
       "      <th>advert_id</th>\n",
       "      <th>advert_location</th>\n",
       "      <th>advertiser_type</th>\n",
       "      <th>breed</th>\n",
       "      <th>pet_age</th>\n",
       "      <th>pet_colour</th>\n",
       "      <th>pet_sex</th>\n",
       "      <th>description</th>\n",
       "      <th>health_checked</th>\n",
       "      <th>microchipped</th>\n",
       "      <th>neutered</th>\n",
       "      <th>vaccinated</th>\n",
       "      <th>worm_treated</th>\n",
       "      <th>registered</th>\n",
       "      <th>original_breeder</th>\n",
       "      <th>viewable_with_mother</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>height</th>\n",
       "      <th>origin</th>\n",
       "      <th>level_jumping</th>\n",
       "      <th>level_dressage</th>\n",
       "      <th>seller_n_adverts</th>\n",
       "      <th>pets_age_in_days</th>\n",
       "      <th>males_in_litter</th>\n",
       "      <th>females_in_litter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Birds</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cats</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dogs</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fish</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horses</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Invertebrates</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rabbits</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reptiles</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodents</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  price    url  phone_verified  email_verified  \\\n",
       "category                                                             \n",
       "Birds          False  False  False           False           False   \n",
       "Cats           False  False  False           False           False   \n",
       "Dogs           False  False  False           False           False   \n",
       "Fish           False  False  False           False           False   \n",
       "Horses         False  False  False           False           False   \n",
       "Invertebrates  False  False  False           False           False   \n",
       "Rabbits        False  False  False           False           False   \n",
       "Reptiles       False  False  False           False           False   \n",
       "Rodents        False  False  False           False           False   \n",
       "\n",
       "               facebook_verified  google_verified  n_images  category  \\\n",
       "category                                                                \n",
       "Birds                      False            False     False     False   \n",
       "Cats                       False            False     False     False   \n",
       "Dogs                       False            False     False     False   \n",
       "Fish                       False            False     False     False   \n",
       "Horses                     False            False     False     False   \n",
       "Invertebrates              False            False     False     False   \n",
       "Rabbits                    False            False     False     False   \n",
       "Reptiles                   False            False     False     False   \n",
       "Rodents                    False            False     False     False   \n",
       "\n",
       "               advert_id  advert_location  advertiser_type  breed  pet_age  \\\n",
       "category                                                                     \n",
       "Birds              False            False            False  False    False   \n",
       "Cats               False            False            False  False    False   \n",
       "Dogs               False            False            False  False    False   \n",
       "Fish               False            False            False  False    False   \n",
       "Horses             False            False            False  False    False   \n",
       "Invertebrates      False            False            False  False    False   \n",
       "Rabbits            False            False            False  False    False   \n",
       "Reptiles           False            False            False  False    False   \n",
       "Rodents            False            False            False  False    False   \n",
       "\n",
       "               pet_colour  pet_sex  description  health_checked  microchipped  \\\n",
       "category                                                                        \n",
       "Birds               False    False        False            True          True   \n",
       "Cats                False    False        False           False         False   \n",
       "Dogs                False    False        False           False         False   \n",
       "Fish                 True     True        False            True          True   \n",
       "Horses              False    False        False            True          True   \n",
       "Invertebrates        True    False        False            True          True   \n",
       "Rabbits             False    False        False            True         False   \n",
       "Reptiles             True    False        False            True          True   \n",
       "Rodents              True    False        False            True          True   \n",
       "\n",
       "               neutered  vaccinated  worm_treated  registered  \\\n",
       "category                                                        \n",
       "Birds              True        True          True        True   \n",
       "Cats              False       False         False       False   \n",
       "Dogs              False       False         False       False   \n",
       "Fish               True        True          True        True   \n",
       "Horses            False        True          True        True   \n",
       "Invertebrates      True        True          True        True   \n",
       "Rabbits           False       False         False        True   \n",
       "Reptiles           True        True          True        True   \n",
       "Rodents            True        True          True        True   \n",
       "\n",
       "               original_breeder  viewable_with_mother  category_1  category_2  \\\n",
       "category                                                                        \n",
       "Birds                      True                  True        True        True   \n",
       "Cats                       True                  True        True        True   \n",
       "Dogs                      False                 False        True        True   \n",
       "Fish                       True                  True        True        True   \n",
       "Horses                     True                  True       False       False   \n",
       "Invertebrates              True                  True        True        True   \n",
       "Rabbits                    True                  True        True        True   \n",
       "Reptiles                   True                  True        True        True   \n",
       "Rodents                    True                  True        True        True   \n",
       "\n",
       "               height  origin  level_jumping  level_dressage  \\\n",
       "category                                                       \n",
       "Birds            True    True           True            True   \n",
       "Cats             True    True           True            True   \n",
       "Dogs             True    True           True            True   \n",
       "Fish             True    True           True            True   \n",
       "Horses          False   False          False           False   \n",
       "Invertebrates    True    True           True            True   \n",
       "Rabbits          True    True           True            True   \n",
       "Reptiles         True    True           True            True   \n",
       "Rodents          True    True           True            True   \n",
       "\n",
       "               seller_n_adverts  pets_age_in_days  males_in_litter  \\\n",
       "category                                                             \n",
       "Birds                     False             False             True   \n",
       "Cats                      False             False            False   \n",
       "Dogs                      False             False            False   \n",
       "Fish                      False             False             True   \n",
       "Horses                    False             False             True   \n",
       "Invertebrates             False             False             True   \n",
       "Rabbits                   False             False             True   \n",
       "Reptiles                  False             False             True   \n",
       "Rodents                   False             False             True   \n",
       "\n",
       "               females_in_litter  \n",
       "category                          \n",
       "Birds                       True  \n",
       "Cats                       False  \n",
       "Dogs                       False  \n",
       "Fish                        True  \n",
       "Horses                      True  \n",
       "Invertebrates               True  \n",
       "Rabbits                     True  \n",
       "Reptiles                    True  \n",
       "Rodents                     True  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This groupby shows which columns are entirely NaNs for each animal type\n",
    "# These columns are most likely to be instances of category 2.\n",
    "pd.set_option('display.max_columns', None)\n",
    "(pets_df.groupby(\"category\").apply(lambda x: x.isna().mean()) == 1)[pets_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I will begin with the horse-specific columns, as these are the clearest instacnes of category 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_1          0\n",
       "category_2         51\n",
       "height              5\n",
       "origin              0\n",
       "level_jumping     242\n",
       "level_dressage    247\n",
       "dtype: int64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df[(pets_df['category'] == 'Horses')][['category_1', \n",
    "                                            'category_2', \n",
    "                                            'height', \n",
    "                                            'origin', \n",
    "                                            'level_jumping',\n",
    "                                            'level_dressage']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_1        19021\n",
       "category_2        19021\n",
       "height            19021\n",
       "origin            19021\n",
       "level_jumping     19021\n",
       "level_dressage    19021\n",
       "dtype: int64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df[(pets_df['category'] != 'Horses')][['category_1', \n",
    "                                            'category_2', \n",
    "                                            'height', \n",
    "                                            'origin', \n",
    "                                            'level_jumping',\n",
    "                                            'level_dressage']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# all horses have values for category_1 and origin, all other animals get a placeholder value\n",
    "pets_df.loc[pets_df['category'] != 'Horses', 'category_1'] = 'Not applicable'\n",
    "pets_df.loc[pets_df['category'] != 'Horses', 'origin'] = 'Not applicable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 48 horses have NaN for category_2\n",
    "pets_df.loc[pets_df['category'] == 'Horses', 'category_2'].value_counts(dropna=False)\n",
    "\n",
    "# as one level of category_2 is the catch-all 'other', this value can be assigned to the NaN rows\n",
    "pets_df.loc[(pets_df['category'] == 'Horses') & (pets_df['category_2'].isna()), 'category_2'] = 'Other'\n",
    "\n",
    "# all other animals get a placeholder\n",
    "pets_df.loc[pets_df['category'] != 'Horses', 'category_2'] = 'Not applicable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19276, 35)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 5 horses are missing height values. I will add placeholders for other animals and drop these 5 horses\n",
    "pets_df.loc[pets_df['category'] != 'Horses', 'height'] = 'Not applicable'\n",
    "pets_df = pets_df[pets_df['height'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# There are only 13 animals in the entire dataset with a jumping level\n",
    "pets_df[pets_df['category'] == 'Horses']['level_jumping'].notna().sum()\n",
    "\n",
    "# I will assume that if a horse does not have a value for jumping level, then it is not a jumping horse.\n",
    "# This can then be treated as a binary variable for horses.\n",
    "pets_df.loc[(pets_df['category'] == 'Horses') & (pets_df['level_jumping'].notna()), 'level_jumping'] = 'Yes'\n",
    "pets_df.loc[(pets_df['category'] == 'Horses') & (pets_df['level_jumping'].isna()), 'level_jumping'] = 'No'\n",
    "\n",
    "# all other animals get a placeholder value\n",
    "pets_df.loc[pets_df['category'] != 'Horses', 'level_jumping'] = 'Not applicable'\n",
    "\n",
    "# renaming the column\n",
    "pets_df.rename(columns={'level_jumping':'jumping_horse'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# There are only 8 animals in the entire dataset with a dressage level\n",
    "pets_df[pets_df['category'] == 'Horses']['level_dressage'].notna().sum()\n",
    "\n",
    "# I will assume that if a horse does not have a value for dressage level, then it is not a dressage horse.\n",
    "# This can then be treated as a binary variable for horses.\n",
    "pets_df.loc[(pets_df['category'] == 'Horses') & (pets_df['level_dressage'].notna()), 'level_dressage'] = 'Yes'\n",
    "pets_df.loc[(pets_df['category'] == 'Horses') & (pets_df['level_dressage'].isna()), 'level_dressage'] = 'No'\n",
    "\n",
    "# all other animals get a placeholder value\n",
    "pets_df.loc[pets_df['category'] != 'Horses', 'level_dressage'] = 'Not applicable'\n",
    "\n",
    "# renaming the column\n",
    "pets_df.rename(columns={'level_dressage':'dressage_horse'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19271, 35)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pet colour\n",
    "\n",
    "# Pets4homes does not record pet colour for fish, invertibrates, reptiles or rodents\n",
    "no_colour = ['Fish', 'Invertebrates', 'Reptiles', 'Rodents']\n",
    "for i in no_colour:\n",
    "    pets_df.loc[(pets_df['category'] == i), 'pet_colour'] = 'Not applicable'\n",
    "\n",
    "# other NaNs are where the seller has not listed the colour\n",
    "pets_df.loc[pets_df['pet_colour'].isna(), 'pet_colour'] = 'Unlisted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pet sex\n",
    "\n",
    "# Pets4homes does not record pet sex for fish\n",
    "pets_df.loc[(pets_df['category'] == 'Fish'), 'pet_sex'] = 'Not applicable'\n",
    "\n",
    "# other NaNs are where the seller has not listed info\n",
    "pets_df.loc[pets_df['pet_sex'].isna(), 'pet_sex'] = 'Unlisted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# health checked, microchipped, vaccinated, worm treated, registered, males in litter, females in litter\n",
    "\n",
    "# Pets4homes does not record any of the above for animals other than dogs and cats\n",
    "categories = pets_df['category'].unique()\n",
    "for i in categories:\n",
    "    if i == 'Cats' or i == 'Dogs':\n",
    "        continue\n",
    "    pets_df.loc[(pets_df['category'] == i), 'health_checked'] = 'Not applicable'\n",
    "    pets_df.loc[(pets_df['category'] == i), 'microchipped'] = 'Not applicable'\n",
    "    pets_df.loc[(pets_df['category'] == i), 'vaccinated'] = 'Not applicable'\n",
    "    pets_df.loc[(pets_df['category'] == i), 'worm_treated'] = 'Not applicable'\n",
    "    pets_df.loc[(pets_df['category'] == i), 'registered'] = 'Not applicable'\n",
    "    pets_df.loc[(pets_df['category'] == i), 'males_in_litter'] = 'Not applicable'\n",
    "    pets_df.loc[(pets_df['category'] == i), 'females_in_litter'] = 'Not applicable'\n",
    "\n",
    "# other NaNs are where the seller has not listed info\n",
    "pets_df.loc[pets_df['health_checked'].isna(), 'health_checked'] = 'Unlisted'\n",
    "pets_df.loc[pets_df['microchipped'].isna(), 'microchipped'] = 'Unlisted'\n",
    "pets_df.loc[pets_df['vaccinated'].isna(), 'vaccinated'] = 'Unlisted'\n",
    "pets_df.loc[pets_df['worm_treated'].isna(), 'worm_treated'] = 'Unlisted'\n",
    "pets_df.loc[pets_df['registered'].isna(), 'registered'] = 'Unlisted'\n",
    "pets_df.loc[pets_df['males_in_litter'].isna(), 'males_in_litter'] = 'Unlisted'\n",
    "pets_df.loc[pets_df['females_in_litter'].isna(), 'females_in_litter'] = 'Unlisted'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# neutered is only applicable for cats, dogs and horses\n",
    "categories = pets_df['category'].unique()\n",
    "for i in categories:\n",
    "    if i in ['Cats', 'Dogs', 'Horses']:\n",
    "        continue\n",
    "    pets_df.loc[(pets_df['category'] == i), 'neutered'] = 'Not applicable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# original breeder and viewable with mother are only applicable to dogs\n",
    "\n",
    "pets_df.loc[(pets_df['category'] != 'Dogs'), 'original_breeder'] = 'Not applicable'\n",
    "pets_df.loc[(pets_df['category'] != 'Dogs'), 'viewable_with_mother'] = 'Not applicable'\n",
    "\n",
    "# other NaNs are where the seller has not listed info\n",
    "pets_df.loc[pets_df['original_breeder'].isna(), 'original_breeder'] = 'Unlisted'\n",
    "pets_df.loc[pets_df['viewable_with_mother'].isna(), 'viewable_with_mother'] = 'Unlisted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>url</th>\n",
       "      <th>phone_verified</th>\n",
       "      <th>email_verified</th>\n",
       "      <th>facebook_verified</th>\n",
       "      <th>google_verified</th>\n",
       "      <th>n_images</th>\n",
       "      <th>category</th>\n",
       "      <th>advert_id</th>\n",
       "      <th>advert_location</th>\n",
       "      <th>advertiser_type</th>\n",
       "      <th>breed</th>\n",
       "      <th>pet_age</th>\n",
       "      <th>pet_colour</th>\n",
       "      <th>pet_sex</th>\n",
       "      <th>description</th>\n",
       "      <th>health_checked</th>\n",
       "      <th>microchipped</th>\n",
       "      <th>neutered</th>\n",
       "      <th>vaccinated</th>\n",
       "      <th>worm_treated</th>\n",
       "      <th>registered</th>\n",
       "      <th>original_breeder</th>\n",
       "      <th>viewable_with_mother</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>height</th>\n",
       "      <th>origin</th>\n",
       "      <th>jumping_horse</th>\n",
       "      <th>dressage_horse</th>\n",
       "      <th>seller_n_adverts</th>\n",
       "      <th>pets_age_in_days</th>\n",
       "      <th>males_in_litter</th>\n",
       "      <th>females_in_litter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, price, url, phone_verified, email_verified, facebook_verified, google_verified, n_images, category, advert_id, advert_location, advertiser_type, breed, pet_age, pet_colour, pet_sex, description, health_checked, microchipped, neutered, vaccinated, worm_treated, registered, original_breeder, viewable_with_mother, category_1, category_2, height, origin, jumping_horse, dressage_horse, seller_n_adverts, pets_age_in_days, males_in_litter, females_in_litter]\n",
       "Index: []"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df[pets_df['worm_treated'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                   0\n",
       "price                   0\n",
       "url                     0\n",
       "phone_verified          0\n",
       "email_verified          0\n",
       "facebook_verified       0\n",
       "google_verified         0\n",
       "n_images                0\n",
       "category                0\n",
       "advert_id               0\n",
       "advert_location         0\n",
       "advertiser_type         0\n",
       "breed                   0\n",
       "pet_age                 0\n",
       "pet_colour              0\n",
       "pet_sex                 0\n",
       "description             0\n",
       "health_checked          0\n",
       "microchipped            0\n",
       "neutered                0\n",
       "vaccinated              0\n",
       "worm_treated            0\n",
       "registered              0\n",
       "original_breeder        0\n",
       "viewable_with_mother    0\n",
       "category_1              0\n",
       "category_2              0\n",
       "height                  0\n",
       "origin                  0\n",
       "jumping_horse           0\n",
       "dressage_horse          0\n",
       "seller_n_adverts        0\n",
       "pets_age_in_days        0\n",
       "males_in_litter         0\n",
       "females_in_litter       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The following columns do not require any cleaning:\n",
    " - url (wont be used in analysis, kept for reference)\n",
    " - advert_id (wont be used in analysis, kept for reference)\n",
    " - n_images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pets_df.to_csv('/Users/lewis/Desktop/GA/DSI25-lessons/projects/project-capstone/data/pets4homes_data_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>phone_verified</th>\n",
       "      <th>email_verified</th>\n",
       "      <th>facebook_verified</th>\n",
       "      <th>google_verified</th>\n",
       "      <th>n_images</th>\n",
       "      <th>seller_n_adverts</th>\n",
       "      <th>pets_age_in_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Birds</th>\n",
       "      <td>401.652116</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.990904</td>\n",
       "      <td>0.150394</td>\n",
       "      <td>0.195876</td>\n",
       "      <td>4.727107</td>\n",
       "      <td>8.451789</td>\n",
       "      <td>417.127237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cats</th>\n",
       "      <td>688.375796</td>\n",
       "      <td>0.996650</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.092406</td>\n",
       "      <td>0.212451</td>\n",
       "      <td>10.324958</td>\n",
       "      <td>2.165271</td>\n",
       "      <td>257.343958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dogs</th>\n",
       "      <td>5323.000409</td>\n",
       "      <td>0.999234</td>\n",
       "      <td>0.998851</td>\n",
       "      <td>0.100472</td>\n",
       "      <td>0.166220</td>\n",
       "      <td>11.691561</td>\n",
       "      <td>1.893400</td>\n",
       "      <td>139.191073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fish</th>\n",
       "      <td>3459.258891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440571</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>3.949287</td>\n",
       "      <td>3.944532</td>\n",
       "      <td>396.391639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horses</th>\n",
       "      <td>2484.712000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>5.348000</td>\n",
       "      <td>2.776000</td>\n",
       "      <td>2357.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Invertebrates</th>\n",
       "      <td>30.211728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>3.543210</td>\n",
       "      <td>5.092593</td>\n",
       "      <td>338.443607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rabbits</th>\n",
       "      <td>49.286462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997008</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>6.145849</td>\n",
       "      <td>2.747943</td>\n",
       "      <td>238.490932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reptiles</th>\n",
       "      <td>155.264887</td>\n",
       "      <td>0.999539</td>\n",
       "      <td>0.996770</td>\n",
       "      <td>0.125981</td>\n",
       "      <td>0.239963</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>11.239040</td>\n",
       "      <td>971.527713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rodents</th>\n",
       "      <td>52.771657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998193</td>\n",
       "      <td>0.353614</td>\n",
       "      <td>0.013855</td>\n",
       "      <td>5.101807</td>\n",
       "      <td>6.169880</td>\n",
       "      <td>202.579484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     price  phone_verified  email_verified  facebook_verified  \\\n",
       "category                                                                        \n",
       "Birds           401.652116        0.999394        0.990904           0.150394   \n",
       "Cats            688.375796        0.996650        0.999162           0.092406   \n",
       "Dogs           5323.000409        0.999234        0.998851           0.100472   \n",
       "Fish           3459.258891        1.000000        1.000000           0.440571   \n",
       "Horses         2484.712000        1.000000        0.996000           0.296000   \n",
       "Invertebrates    30.211728        1.000000        1.000000           0.401235   \n",
       "Rabbits          49.286462        1.000000        0.997008           0.290202   \n",
       "Reptiles        155.264887        0.999539        0.996770           0.125981   \n",
       "Rodents          52.771657        1.000000        0.998193           0.353614   \n",
       "\n",
       "               google_verified   n_images  seller_n_adverts  pets_age_in_days  \n",
       "category                                                                       \n",
       "Birds                 0.195876   4.727107          8.451789        417.127237  \n",
       "Cats                  0.212451  10.324958          2.165271        257.343958  \n",
       "Dogs                  0.166220  11.691561          1.893400        139.191073  \n",
       "Fish                  0.017433   3.949287          3.944532        396.391639  \n",
       "Horses                0.016000   5.348000          2.776000       2357.900000  \n",
       "Invertebrates         0.018519   3.543210          5.092593        338.443607  \n",
       "Rabbits               0.013463   6.145849          2.747943        238.490932  \n",
       "Reptiles              0.239963   4.636364         11.239040        971.527713  \n",
       "Rodents               0.013855   5.101807          6.169880        202.579484  "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df.groupby('category').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "health_checked_Unlisted           0.010378\n",
       "health_checked_no                 9.781537\n",
       "health_checked_yes               49.442167\n",
       "health_checked_nan                0.000000\n",
       "microchipped_no                  19.822531\n",
       "microchipped_yes                 39.411551\n",
       "microchipped_nan                  0.000000\n",
       "vaccinated_no                    15.053708\n",
       "vaccinated_yes                   44.180375\n",
       "vaccinated_nan                    0.000000\n",
       "worm_treated_Unlisted             0.010378\n",
       "worm_treated_no                   4.893363\n",
       "worm_treated_yes                 54.330341\n",
       "worm_treated_nan                  0.000000\n",
       "original_breeder_Unlisted        12.075139\n",
       "original_breeder_no               0.902911\n",
       "original_breeder_yes             27.668517\n",
       "original_breeder_nan              0.000000\n",
       "viewable_with_mother_Unlisted     0.041513\n",
       "viewable_with_mother_no           4.384827\n",
       "viewable_with_mother_yes         36.220227\n",
       "viewable_with_mother_nan          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(pets_df[['health_checked',\n",
    "                                  'microchipped',\n",
    "                                  'vaccinated',\n",
    "                                  'worm_treated',\n",
    "                                  'original_breeder',\n",
    "                                  'viewable_with_mother']],\n",
    "              drop_first = True,\n",
    "              dummy_na = True)\n",
    "\n",
    "dummies.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                   0\n",
       "price                   0\n",
       "url                     0\n",
       "phone_verified          0\n",
       "email_verified          0\n",
       "facebook_verified       0\n",
       "google_verified         0\n",
       "n_images                0\n",
       "category                0\n",
       "advert_id               0\n",
       "advert_location         0\n",
       "advertiser_type         0\n",
       "breed                   0\n",
       "pet_age                 0\n",
       "pet_colour              0\n",
       "pet_sex                 0\n",
       "description             0\n",
       "health_checked          0\n",
       "microchipped            0\n",
       "neutered                0\n",
       "vaccinated              0\n",
       "worm_treated            0\n",
       "registered              0\n",
       "original_breeder        0\n",
       "viewable_with_mother    0\n",
       "category_1              0\n",
       "category_2              0\n",
       "height                  0\n",
       "origin                  0\n",
       "jumping_horse           0\n",
       "dressage_horse          0\n",
       "seller_n_adverts        0\n",
       "pets_age_in_days        0\n",
       "males_in_litter         0\n",
       "females_in_litter       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pets_df_dictionary = {\n",
    "    'title' : 'The title of the listing',\n",
    "    'price' : 'The price of the listed pet',\n",
    "    'url' : 'The URL of the listing',\n",
    "    'phone_verified' : \"Whether the seller's profile has been verified by phone\",\n",
    "    'email_verified' : \"Whether the seller's profile has been verified by email\",\n",
    "    'facebook_verified' : \"Whether the seller's profile has been verified by Facebook\",\n",
    "    'google_verified' : \"Whether the seller's profile has been verified by Google\",\n",
    "    'n_images' : 'The number of images included in the listing',\n",
    "    'category' : 'The type of animal',\n",
    "    'advert_id' : \"The listing's unique ID\",\n",
    "    'advert_location' : \"The location of the seller\",\n",
    "    'advertiser_type' : 'The type of seller',\n",
    "    'breed' : 'The breed of the pet(s) being sold',\n",
    "    'pet_age' : 'The age of the pet(s) being sold',\n",
    "    'pet_colour' : 'The colour of the pet(s) being sold',\n",
    "    'pet_sex' : 'The sex of the pet(s) being sold',\n",
    "    'description' : 'The listing description provided by the seller',\n",
    "    'health_checked' : 'Whether the pets(s) have been health checked',\n",
    "    'microchipped' : 'Whether the pets(s) have been microchipped',\n",
    "    'neutered' : \"Whether the pet(s) have been neutered\",\n",
    "    'vaccinated' : \"Whether the pet(s) have been vaccinated\",\n",
    "    'worm_treated' : \"Whether the pet(s) have been worm treated\",\n",
    "    'registered' : \"Whether the pet(s) are registered with a breeders or owners club/society\",\n",
    "    'original_breeder' : 'Whether the seller is the original breeder of the pet',\n",
    "    'viewable_with_mother' : \"Whether the pet is viewable with it's mother\",\n",
    "    'category_1' : 'The primary category of a horse', \n",
    "    'category_2' : 'The secondary category of a horse',\n",
    "    'height' : 'The height of a horse (measured in hands)',\n",
    "    'origin' : 'The origin of a horse',\n",
    "    'jumping_horse' : 'Whether a horse does show jumping',\n",
    "    'dressage_horse' : 'Wether a horse does dressage',\n",
    "    'seller_n_adverts' : 'The number of adverts that seller had at the time of data collection',\n",
    "    'pets_age_in_days' : \"The age of the pet(s), measured in days\",\n",
    "    'males_in_litter' : \"The number of male pets in the litter\",\n",
    "    'females_in_litter' : \"The number of female pets in the litter\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Bonus\n",
    "\n",
    "4. Document your project goals (revise from your initial pitch)\n",
    "   - Articulate “Specific aim”\n",
    "   - Outline proposed methods and models\n",
    "   - Define risks & assumptions\n",
    "\n",
    "5. Create a blog post of at least 500 words that describes your work so far. Link to it in your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "## Deliverable Format & Submission\n",
    "\n",
    "- Table, file, or database with relevant text file or notebook description.\n",
    "\n",
    "---\n",
    "\n",
    "## Suggested Ways to Get Started\n",
    "\n",
    "- Review your initial proposal topic and feedback, and revise accordingly.\n",
    "- Spend time with your data and verify that it can help you accomplish the goals you set out to pursue.\n",
    "- If not, document how you intend to either change those goals.\n",
    "- Alternatively, go find some additional data and/or try another source.\n",
    "\n",
    "---\n",
    "\n",
    "## Useful Resources\n",
    "\n",
    "- [Exploratory Data Analysis](http://insightdatascience.com/blog/eda-and-graphics-eli-bressert.html)\n",
    "- [Best practices for data documentation](https://www.dataone.org/all-best-practices)\n",
    "\n",
    "---\n",
    "\n",
    "## Project Feedback + Evaluation\n",
    "\n",
    "[Attached here is a complete rubric for this project.](./capstone-part-02-rubric.md)\n",
    "\n",
    "Your instructors will score each of your technical requirements using the scale below:\n",
    "\n",
    "Score  | Expectations\n",
    "--- | ---\n",
    "**0** | _Incomplete._\n",
    "**1** | _Does not meet expectations._\n",
    "**2** | _Meets expectations, good job!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
